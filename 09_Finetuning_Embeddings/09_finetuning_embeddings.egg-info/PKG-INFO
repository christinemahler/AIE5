Metadata-Version: 2.2
Name: 09-finetuning-embeddings
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.13
Description-Content-Type: text/markdown
Requires-Dist: accelerate>=1.3.0
Requires-Dist: beautifulsoup4>=4.13.3
Requires-Dist: datasets>=3.2.0
Requires-Dist: faiss-cpu>=1.10.0
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: ipywidgets>=8.1.5
Requires-Dist: langchain>=0.3.18
Requires-Dist: langchain-community>=0.3.17
Requires-Dist: langchain-core>=0.3.34
Requires-Dist: langchain-huggingface>=0.1.2
Requires-Dist: langchain-openai>=0.3.4
Requires-Dist: langchain-text-splitters>=0.3.6
Requires-Dist: lxml>=5.3.1
Requires-Dist: nltk==3.9.1
Requires-Dist: pyarrow>=19.0.0
Requires-Dist: pymupdf>=1.25.3
Requires-Dist: python-pptx==1.0.2
Requires-Dist: sentence-transformers>=3.4.1
Requires-Dist: transformers[torch]>=4.48.3
Requires-Dist: wandb>=0.19.6

<p align = "center" draggable=”false” ><img src="https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719" 
     width="200px"
     height="auto"/>
</p>

## <h1 align="center" id="heading">Session 9: Fine-tuning Embeddings</h1>

| 🤓 Pre-work | 📰 Session Sheet | ⏺️ Recording     | 🖼️ Slides        | 👨‍💻 Repo         | 📝 Homework      | 📁 Feedback       |
|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|
| [Session 9: Pre-Work](https://www.notion.so/Session-9-Fine-Tuning-Embeddings-or-Domain-Adapted-Retrieval-189cd547af3d80e2a20af073060f2c0c?pvs=4#189cd547af3d81048f71c349e2c5ca9d)| [Session 9: Fine-Tuning Embeddings or Domain-Adapted Retrieval](https://www.notion.so/Session-9-Fine-Tuning-Embeddings-or-Domain-Adapted-Retrieval-189cd547af3d80e2a20af073060f2c0c) | Coming Soon! | Coming Soon! | Coming Soon!| Coming Soon! | [AIE5 Feedback 2/11](https://forms.gle/FgtkahAXGivuZWsV8) |

In today's assignment, we'll be fine-tuning embeddings!

- 🤝 Breakout Room #1:
  - Task 1: Dependencies and Boilerplate
  - Task 2: Loading Data
  - Task 3: Constructing a Fine-tuning Dataset
  - Task 4: Fine-tuning `snowflake-arctic-embed-l`
  - Task 5: Evaluating our Retriever
    
The notebook Colab link is located [here](https://colab.research.google.com/drive/1tNc1uzPE1tgjswmLLuYczOZtxCw1Ifac?usp=sharing)

## Ship 🚢

The completed notebook!

#### 🏗️ BONUS ACTIVITY (FULL MARKS IF COMPLETED IN LIEU OF ABOVE NOTEBOOK):

Using your own source data (from multiple sources) fine-tune an embedding model by synthetically generating 100 question/context using the Ragas Knowledge Graph Approach.

Compare and contrast this model to a model fine-tuned using the naive approach found in the notebook. 

> NOTE: You can use any embedding model and fine-tuning framework that you desire!

### Deliverables

- A short Loom of the notebook, and a 1min. walkthrough of the application in full

## Share 🚀

Make a social media post about your final application!

### Deliverables

- Make a post on any social media platform about what you built!

Here's a template to get you started:

```
🚀 Exciting News! 🚀

I am thrilled to announce that I have just built and shipped fine-tuning embeddings! 🎉🤖

🔍 Three Key Takeaways:
1️⃣ 
2️⃣ 
3️⃣ 

Let's continue pushing the boundaries of what's possible in the world of AI and question-answering. Here's to many more innovations! 🚀
Shout out to @AIMakerspace !

#LangChain #QuestionAnswering #RetrievalAugmented #Innovation #AI #TechMilestone

Feel free to reach out if you're curious or would like to collaborate on similar projects! 🤝🔥
```
