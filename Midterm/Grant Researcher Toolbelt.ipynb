{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall of Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import requests\n",
    "import json\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "import pprint\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from ftplib import FTP\n",
    "import tarfile\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import subprocess\n",
    "import pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"QDRANT_API_KEY\"] = getpass.getpass(\"Please enter your Qdrant API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Qdrant Vector Store Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = \"https://e788c0ea-f5df-4d96-85ac-350da677aadf.us-west-2-0.aws.cloud.qdrant.io\"\n",
    "\n",
    "# Opportunities\n",
    "opportunities_qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"opportunities\",\n",
    "    url=qdrant_url,\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")\n",
    "\n",
    "# Projects\n",
    "projects_qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"projects\",\n",
    "    url=qdrant_url,\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities_retriever = opportunities_qdrant.as_retriever(search_kwargs={\"k\": 5})\n",
    "projects_retriever = projects_qdrant.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities_rag_prompt_template = \"\"\"\\\n",
    "Use only the provided context to answer the user's question. If an opportunity id is provided, use only the context for that opportunity. Include the opportunity id, name, and a working url in every response.\n",
    "\n",
    "If the user asks you to evaluate the study complexity or create a budget, provide a complexity score of high, medium, or low and a reason for all of the following categories:\n",
    "1) Regulatory and Compliance (rank higher if study requires compliance with multiple regulations and provide examples)\n",
    "2) Data Collection and Management (identify data elements needed, data complexity, data sensitivity, and data collection frequency)\n",
    "3) Statistical Analysis and Manuscript Development (provide examples)\n",
    "4) Information Technology (identify data collection services and equipment needed along with software licenses and subscriptions)\n",
    "5) Operational (includes project administration and site onboarding, coordination and training)\n",
    "6) Financial (includes budget management and effort allocation over entire duration of project; rank higher if more resources are required)\n",
    "\n",
    "If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "opportunities_rag_prompt = ChatPromptTemplate.from_template(opportunities_rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_rag_prompt_template = \"\"\"\\\n",
    "Use only the provided context to answer the user's question. If a specific project is named, use only the context for that project. Include the name of the projects in your response, and provide a working url to the project details.\n",
    "\n",
    "If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "projects_rag_prompt = ChatPromptTemplate.from_template(projects_rag_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate RAG LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "rag_llm = ChatOpenAI(model=\"gpt-4o-mini\", tags=[\"rag_llm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "opportunities_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | opportunities_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | opportunities_rag_prompt | rag_llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "projects_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | projects_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | projects_rag_prompt | rag_llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Opportunity ID:** PA-25-147  \\n**Name:** NIDDK High Risk Multi-Center Clinical Study Cooperative Agreement (U01 Clinical Trial Required)  \\n**URL:** [NIDDK High Risk Multi-Center Clinical Study](https://grants.nih.gov/grants/guide/rfa-files/RFA-PA-25-147.html)  \\n\\n**Complexity Evaluation:**\\n\\n1) **Regulatory and Compliance:** **High**  \\n   The study involves compliance with various NIH regulations and requirements for clinical trials, including adherence to Good Clinical Practice (GCP) and possibly other regulations pertaining to patient safety and data sharing, particularly for multi-center studies.\\n\\n2) **Data Collection and Management:** **High**  \\n   The study will likely collect a variety of data elements given its multi-center nature, including patient demographics, treatment regimens, and clinical outcomes. Data complexity will be high due to the need for standardization across multiple sites. Sensitivity will be elevated, particularly concerning personal health data, requiring rigorous data protection measures.\\n\\n3) **Statistical Analysis and Manuscript Development:** **High**  \\n   The statistical analysis will require complex methodologies to account for variability between different clinical centers and conduct meta-analyses. The development of manuscripts subsequently will involve addressing diverse datasets and ensuring that results are comprehensively interpreted to influence clinical practice, necessitating high-level expertise.\\n\\n4) **Information Technology:** **Medium**  \\n   A robust IT infrastructure will be necessary to support data collection across multiple sites. This includes data collection services, secure servers for data storage, and potentially software licenses for data analysis tools. However, the complexity may be lower compared to studies with extensive technology integration.\\n\\n5) **Operational:** **High**  \\n   The operational complexity is likely to be high due to the need for extensive project administration, including the coordination of multiple clinical sites, training of site staff, and ensuring compliance with study protocols across the board.\\n\\n6) **Financial:** **High**  \\n   The budget management will require careful planning as funding will need to cover multiple centers, research personnel, and operational costs over the entire duration of the project. Significant resources will be required to support the multi-center aspects of this study.\\n\\nOverall, the complexity score for the PA-25-147 funding opportunity is **High**.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opportunities_rag_chain.invoke({\"question\" : \"evaluate the study complexity of the PA-25-147 funding opportunity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a summary of the University of Utah projects by year:\\n\\n### 2021\\n- **Project Title:** University of Utah Center of Excellence in ELSI research (UCEER)\\n  - **Project Number:** 5RM1HG009037-06\\n  - **Award Amount:** $991,250\\n  - **Abstract:** The project focuses on issues relevant to population-based genetic testing and screening, with an emphasis on newborn screening, prenatal screening, and genetic disabilities, including community support and legal/policy issues.\\n  - **Project Detail:** [View Project](https://reporter.nih.gov/project-details/10226042)\\n\\n### 2022\\n- **Project Title:** IMSD at the University of Utah (IMSD@U2)\\n  - **Project Number:** 1T32GM139805-01A1\\n  - **Award Amount:** $219,809\\n  - **Abstract:** Aims to train and launch diverse students into successful PhD careers while improving recruitment and retention of underrepresented students in the biomedical workforce.\\n  - **Project Detail:** [View Project](https://reporter.nih.gov/project-details/10360802)\\n\\n### 2023\\n- **Project Title:** University of Utah Center of Excellence in ELSI research (UCEER)\\n  - **Project Number:** 5RM1HG009037-08\\n  - **Award Amount:** $991,250\\n  - **Abstract:** Renewal grant focusing on ELSI issues in population genetic testing, enhancing educational activities and informed decision-making in healthcare settings.\\n  - **Project Detail:** [View Project](https://reporter.nih.gov/project-details/10632012)\\n\\n### 2024\\n- **Project Title:** University of Utah Center of Excellence in ELSI research (UCEER)\\n  - **Project Number:** 3RM1HG009037-08S1\\n  - **Award Amount:** $109,589\\n  - **Abstract:** Renewal focusing on ELSI issues particularly in genetic disabilities, community adaptation, and the implications of population-based testing.\\n  - **Project Detail:** [View Project](https://reporter.nih.gov/project-details/11090190)\\n\\nPlease let me know if you need more information on any specific project!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_rag_chain.invoke({\"question\" : \"summarize the University of Utah projects by year\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def retrieve_opportunities_information(\n",
    "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
    "    ):\n",
    "  \"\"\"Use Retrieval Augmented Generation to retrieve information about NIH funding opportunities\"\"\"\n",
    "  return opportunities_rag_chain.invoke({\"question\" : query})\n",
    "\n",
    "@tool\n",
    "def retrieve_projects_information(\n",
    "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
    "    ):\n",
    "  \"\"\"Use Retrieval Augmented Generation to retrieve information about NIH projects\"\"\"\n",
    "  return projects_rag_chain.invoke({\"question\" : query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Research Team State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "class ResearchTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Supervisor Agent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities_agent = create_agent(\n",
    "    llm,\n",
    "    [retrieve_opportunities_information],\n",
    "    \"You are a research assistant who can provide specific information on NIH funding opportunties. You must only respond with information about the opportunities related to the request. In addition to your main response, include the opportunity id, name and link.\",\n",
    ")\n",
    "opportunities_node = functools.partial(agent_node, agent=opportunities_agent, name=\"OpportunitiesInformationRetriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_agent = create_agent(\n",
    "    llm,\n",
    "    [retrieve_projects_information],\n",
    "    \"You are a research assistant who can provide specific information on NIH projects. You must only respond with information about the projects related to the request. In addition to your main response, include the project name and link.\",\n",
    ")\n",
    "projects_node = functools.partial(agent_node, agent=projects_agent, name=\"ProjectsInformationRetriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/0my2dcr50j3g01czsw6gr97w0000gn/T/ipykernel_24239/1110033859.py:62: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
      "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
     ]
    }
   ],
   "source": [
    "supervisor_agent = create_team_supervisor(\n",
    "    llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  OpportunitiesInformationRetriever, ProjectsInformationRetriever. Given the following user request,\"\n",
    "    \" determine the content type to be researched and respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. \"\n",
    "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
    "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
    "    \" When finished, respond with FINISH.\"),\n",
    "    [\"OpportunitiesInformationRetriever\", \"ProjectsInformationRetriever\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x312d9e7b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_graph = StateGraph(ResearchTeamState)\n",
    "\n",
    "research_graph.add_node(\"OpportunitiesInformationRetriever\", opportunities_node)\n",
    "research_graph.add_node(\"ProjectsInformationRetriever\", projects_node)\n",
    "research_graph.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x312d9e7b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_graph.add_edge(\"OpportunitiesInformationRetriever\", \"supervisor\")\n",
    "research_graph.add_edge(\"ProjectsInformationRetriever\", \"supervisor\")\n",
    "research_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\"OpportunitiesInformationRetriever\": \"OpportunitiesInformationRetriever\", \"ProjectsInformationRetriever\": \"ProjectsInformationRetriever\", \"FINISH\": END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_graph.set_entry_point(\"supervisor\")\n",
    "chain = research_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Graph Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(chain.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Team Members\n",
    "team_members doesn't get implicitly passed to the chat prompt template, so this was my workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_chain(message: str):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(research_graph.nodes),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "research_chain = enter_chain | chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'OpportunitiesInformationRetriever'}}\n",
      "---\n",
      "{'OpportunitiesInformationRetriever': {'messages': [HumanMessage(content='The NIH funding opportunity PA-25-147, titled \"NIDDK High Risk Multi-Center Clinical Study Cooperative Agreement (U01 Clinical Trial Required) Part 2,\" presents a high level of complexity across several aspects. Here\\'s a breakdown:\\n\\n1. **Regulatory and Compliance:** High complexity due to multi-center clinical trial requirements, including adherence to FDA regulations and GCP guidelines.\\n2. **Data Collection and Management:** High complexity, necessitating robust data management systems to handle diverse and sensitive data across multiple sites.\\n3. **Statistical Analysis and Manuscript Development:** High complexity, involving sophisticated statistical analyses to evaluate interventions across diverse populations and sites.\\n4. **Information Technology:** Medium complexity, with essential IT services for data management and security.\\n5. **Operational:** High complexity due to the need for effective coordination and training across multiple sites.\\n6. **Financial:** High complexity in budget management to cover extensive multi-center expenses.\\n\\nThese aspects contribute to the overall high complexity of managing and implementing this NIH funded project.\\n\\nFor more details, you can access the full announcement through this link: [PA-25-147 Announcement](https://www.niaid.nih.gov/sites/default/files/pa-25-147.pdf).', additional_kwargs={}, response_metadata={}, name='OpportunitiesInformationRetriever')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in research_chain.stream(\n",
    "    \"Evaluate the study complexity for the PA-25-147 opportunity\", {\"recursion_limit\": 10}\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget Analysis State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BudgetTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Budget Team Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def do_nothing(\n",
    "    input_text: Annotated[str, \"Any input text.\"]\n",
    ") -> Annotated[str, \"A placeholder response indicating the tool does nothing.\"]:\n",
    "    \"\"\"\n",
    "    A LangChain tool that does nothing and returns a generic response.\n",
    "    Useful as a placeholder for debugging or tool testing.\n",
    "    \"\"\"\n",
    "    return \"This tool does nothing. You provided: \" + input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "personnel_budget_agent = create_agent(\n",
    "    llm,\n",
    "    [do_nothing],\n",
    "    (\"You are an expert at drafting NIH  budgets. You use the provided study complexity \"\n",
    "     \"to calculate the effort allocation percentage by study year for all of the following roles: \"\n",
    "     \"DCC Principal Investigator, DCC Co-Principal Investigator, Clinical Data Managers, Stats, Clinical \"\n",
    "     \"Project Manager, Business Project Manager, Software Engineering, IT Project Manager, IT Operations, \"\n",
    "     \"Ops Leader, Administrative Program Assistant, Regulatory and Quality Assurance Manager, Finance, \"\n",
    "     \"Medical Monitor, Business Intelligence, Stats Manager, Clinical Data Management Manager, and IT Manager \"\n",
    "     \"If a role is not required, it will be left out of the budget. \"\n",
    "     \"Effort allocations should be listed in a table format with the roles listed in rows and the study \"\n",
    "     \"years listed in columns. It should additionally follow the detailed NIH budget guidelines.\"),\n",
    ")\n",
    "personnel_budget_node = functools.partial(\n",
    "    agent_node, agent=personnel_budget_agent, name=\"PersonnelBudget\"\n",
    ")\n",
    "\n",
    "budget_analysis_supervisor = create_team_supervisor(\n",
    "    llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the \"\n",
    "    \"following workers: PersonnelBudget. \"\n",
    "    \"You should always verify the technical \"\n",
    "    \"contents after any edits are made. \"\n",
    "    \"Given the user request, \"\n",
    "    \"respond with the worker to act next. \"\n",
    "    \"task and respond with their results and status. \"\n",
    "    \"Allow each worker to complete only one draft before completing their assignment. \"\n",
    "    \"When your team's work is complete, \"\n",
    "    \"you must respond with FINISH.\"),\n",
    "    [\"PersonnelBudget\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_analysis_graph = StateGraph(BudgetTeamState)\n",
    "budget_analysis_graph.add_node(\"PersonnelBudget\", personnel_budget_node)\n",
    "budget_analysis_graph.add_node(\"supervisor\", budget_analysis_supervisor)\n",
    "\n",
    "budget_analysis_graph.add_edge(\"PersonnelBudget\", \"supervisor\")\n",
    "\n",
    "budget_analysis_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"PersonnelBudget\": \"PersonnelBudget\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "budget_analysis_graph.set_entry_point(\"supervisor\")\n",
    "chain = budget_analysis_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_budget_chain(message: str, members: List[str]):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(members),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "budget_analysis_chain = (\n",
    "    functools.partial(enter_budget_chain, members=budget_analysis_graph.nodes)\n",
    "    | budget_analysis_graph.compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'PersonnelBudget'}}\n",
      "---\n",
      "{'PersonnelBudget': {'messages': [HumanMessage(content='To craft a precise NIH budget, I require specific details regarding your study, such as its complexity, duration, phases, number and types of participants, study sites, and any special requirements or equipment needed. This information will allow me to accurately allocate effort percentages for each role involved in the project.\\n\\nCould you please provide more context or specific details about the study for which you need the budget? This will enable me to assist you effectively.', additional_kwargs={}, response_metadata={}, name='PersonnelBudget')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'PersonnelBudget'}}\n",
      "---\n",
      "{'PersonnelBudget': {'messages': [HumanMessage(content='To assist effectively in creating an NIH budget, specific details regarding the study are required, such as its complexity, duration, phases, number and types of participants, study sites, and any special requirements or equipment needed. These details are crucial to accurately allocate effort percentages for each role involved in the project.\\n\\nCould you please provide more context or specific details about the study for which you need the budget? This will enable me to appropriately calculate and allocate the efforts.', additional_kwargs={}, response_metadata={}, name='PersonnelBudget')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'PersonnelBudget'}}\n",
      "---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbudget_analysis_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreate a budget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3405\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3401\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3402\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3405\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3392\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3387\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3389\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3392\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3395\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3396\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3397\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2195\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2195\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3355\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3353\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3355\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1429\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1677\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:462\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    459\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    460\u001b[0m )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langgraph/utils/runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 226\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m, in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magent_node\u001b[39m(state, agent, name):\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39mname)]}\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1624\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1634\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1332\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m   1330\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m-> 1332\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1340\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1358\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1358\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:465\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3405\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3401\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3402\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3405\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3392\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3387\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3389\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3392\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3395\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3396\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3397\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2195\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2195\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3355\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3353\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3355\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1411\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m final: Input\n\u001b[1;32m   1409\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[1;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[1;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[1;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[1;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5559\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   5554\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5555\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   5556\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5557\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   5558\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 5559\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   5560\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5561\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5562\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5563\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1429\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:422\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    417\u001b[0m         e,\n\u001b[1;32m    418\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    419\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    420\u001b[0m         ),\n\u001b[1;32m    421\u001b[0m     )\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:400\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:727\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m    726\u001b[0m     is_first_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/openai/_streaming.py:46\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[0;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/openai/_streaming.py:58\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[1;32m     56\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[0;32m---> 58\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[DONE]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/openai/_streaming.py:50\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_bytes())\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/openai/_streaming.py:280\u001b[0m, in \u001b[0;36mSSEDecoder.iter_bytes\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/openai/_streaming.py:291\u001b[0m, in \u001b[0;36mSSEDecoder._iter_chunks\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[1;32m    290\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Desktop/AIE5/Midterm/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for s in budget_analysis_chain.stream(\n",
    "    \"Create a budget\",\n",
    "    {\"recursion_limit\": 10},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Writing State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from pathlib import Path\n",
    "\n",
    "class DocWritingState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: str\n",
    "    next: str\n",
    "    current_files: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Document Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "from typing_extensions import TypedDict\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "os.makedirs('data/Documents', exist_ok=True)\n",
    "\n",
    "def create_random_subdirectory():\n",
    "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
    "    subdirectory_path = os.path.join('data/Documents', random_id)\n",
    "    os.makedirs(subdirectory_path, exist_ok=True)\n",
    "    return subdirectory_path\n",
    "\n",
    "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ] = {},\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_writer_agent = create_agent(\n",
    "    llm,\n",
    "    [write_document, edit_document, read_document],\n",
    "    (\"You are an expert writing documents. You may only use the information provided by the research and budget analysis \"\n",
    "     \"teams to generate your document. You do not need to collect any more information at this point to produce your document. \"\n",
    "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
    ")\n",
    "context_aware_budget_writer_agent = prelude | budget_writer_agent\n",
    "budget_writing_node = functools.partial(\n",
    "    agent_node, agent=context_aware_budget_writer_agent, name=\"BudgetWrite\"\n",
    ")\n",
    "\n",
    "doc_writing_supervisor = create_team_supervisor(\n",
    "    llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: {team_members}. You should always verify the technical\"\n",
    "    \" contents after any edits are made. \"\n",
    "    \"Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When each team is finished,\"\n",
    "    \" you must respond with FINISH.\"),\n",
    "    [\"BudgetWriter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "authoring_graph = StateGraph(DocWritingState)\n",
    "authoring_graph.add_node(\"BudgetWriter\", budget_writing_node)\n",
    "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
    "\n",
    "authoring_graph.add_edge(\"BudgetWriter\", \"supervisor\")\n",
    "\n",
    "authoring_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"BudgetWriter\": \"BudgetWriter\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "authoring_graph.set_entry_point(\"supervisor\")\n",
    "chain = authoring_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(chain.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_chain(message: str, members: List[str]):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(members),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "authoring_chain = (\n",
    "    functools.partial(enter_chain, members=authoring_graph.nodes)\n",
    "    | authoring_graph.compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'BudgetWriter'}}\n",
      "---\n",
      "{'BudgetWriter': {'messages': [HumanMessage(content='The budget document for funding opportunity PA-25-147 has been successfully created and saved. If you need any further details or revisions to the document, please let me know!', additional_kwargs={}, response_metadata={}, name='BudgetWrite')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in authoring_chain.stream(\n",
    "    \"Create a budget document for funding opportunity PA-25-147.\",\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Agent to Rule Them All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "supervisor_node = create_team_supervisor(\n",
    "    llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following teams: {team_members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. \"\n",
    "    \"When all workers are finished,\"\n",
    "    \" you must respond with FINISH.\",\n",
    "    [\"Research team\", \"Budget Analysis team\", \"Documents team\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "def get_last_message(state: State) -> str:\n",
    "    return state[\"messages\"][-1].content\n",
    "\n",
    "def join_graph(response: dict):\n",
    "    return {\"messages\": [response[\"messages\"][-1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x3181c2520>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_graph = StateGraph(State)\n",
    "\n",
    "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
    "super_graph.add_node(\"Budget Analysis team\", get_last_message | budget_analysis_chain | join_graph)\n",
    "super_graph.add_node(\n",
    "    \"Documents team\", get_last_message | authoring_chain | join_graph\n",
    ")\n",
    "super_graph.add_node(\"supervisor\", supervisor_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_graph.add_edge(\"Research team\", \"supervisor\")\n",
    "super_graph.add_edge(\"Budget Analysis team\", \"supervisor\")\n",
    "super_graph.add_edge(\"Documents team\", \"supervisor\")\n",
    "super_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"Documents team\": \"Documents team\",\n",
    "        \"Budget Analysis team\": \"Budget Analysis team\",\n",
    "        \"Research team\": \"Research team\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "super_graph.set_entry_point(\"supervisor\")\n",
    "super_graph = super_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Research team'}}\n",
      "---\n",
      "{'Research team': {'messages': [HumanMessage(content='The following projects were not among the 10 most recent NIH-funded projects at the University of Utah but are significant ongoing initiatives:\\n\\n1. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2023)**\\n   - **Principal Investigator:** Robin K Ohls\\n   - **Award:** $344,885\\n   - Detailed information can be found [here](https://reporter.nih.gov/project-details/10682083).\\n\\n2. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2021)**\\n   - **Principal Investigator:** Robin K Ohls\\n   - **Award:** $281,382\\n   - Detailed information can be found [here](https://reporter.nih.gov/project-details/10348097).\\n\\n3. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2020)**\\n   - **Principal Investigator:** Robin K Ohls\\n   - **Award:** $281,382\\n   - Detailed information can be found [here](https://reporter.nih.gov/project-details/9899864).\\n\\nThese projects, managed by Robin K Ohls, focus on neonatal research and involve substantial research activities across various fiscal years.', additional_kwargs={}, response_metadata={}, name='ProjectsInformationRetriever')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'Research team'}}\n",
      "---\n",
      "{'Research team': {'messages': [HumanMessage(content='These projects mentioned are crucial parts of neonatal research initiatives at the University of Utah under the direction of Robin K Ohls. They contribute significantly to advancing knowledge and treatments in neonatology through the NICHD Cooperative Multicenter Neonatal Research Network.\\n\\n1. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2023)**\\n   - The 2023 project continues ongoing research, contributing to neonatal research networks that aim to improve the health outcomes of newborns needing intensive medical attention soon after birth.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2023)](https://reporter.nih.gov/project-details/10682083)\\n\\n2. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2021)**\\n   - In 2021, the project focused on similar research themes, aiming to enhance clinical care practices and outcomes through multicenter cooperation.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2021)](https://reporter.nih.gov/project-details/10348097)\\n\\n3. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2020)**\\n   - The 2020 initiative was another critical installment in this series of research efforts, focusing on high-risk newborn research.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2020)](https://reporter.nih.gov/project-details/9899864)\\n\\nThese projects help in building a comprehensive base of scientific knowledge and clinical methodologies to tackle neonatal challenges effectively.', additional_kwargs={}, response_metadata={}, name='ProjectsInformationRetriever')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'Research team'}}\n",
      "---\n",
      "{'Research team': {'messages': [HumanMessage(content=\"I'm specialized in providing specific information on NIH projects. Here are the details related to the projects you mentioned:\\n\\n1. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2023)**\\n   - Description: The 2023 project continues the valuable work of previous years, focusing on the NICHD's objectives to conduct multicenter clinical trials and observational studies in neonatology for new strategies to improve newborn health outcomes. This project's emphasis on collaboration and data sharing across centers is instrumental in enhancing neonatal care nationwide.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2023)](https://reporter.nih.gov/project-details/10682083)\\n\\n2. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2021)**\\n   - Description: In 2021, this project provided a platform for testing and refining various clinical interventions. It aimed to establish best practices that could be universally recommended for care in the neonatal intensive care units (NICUs), thereby improving both short-term and long-term outcomes for neonates.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2021)](https://reporter.nih.gov/project-details/10348097)\\n\\n3. **NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2020)**\\n   - Description: The 2020 project focused on rigorous research into the care practices for high-risk newborns. Its objective was to improve morbidity and mortality rates through enhanced clinical practices derived from research findings, sharing insights that can benefit neonatal care practices nationally.\\n   - **Project Name and Link:** [NICHD Cooperative Multicenter Neonatal Research Network - Utah Center (2020)](https://reporter.nih.gov/project-details/9899864)\\n\\nThese projects are significant in their collective efforts to refine clinical strategies and enhance the survivability and quality of life for neonates in critical conditions. Each project builds upon the foundation of the last, making substantial contributions to the field of neonatal research and care.\", additional_kwargs={}, response_metadata={}, name='ProjectsInformationRetriever')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
    "\n",
    "#content = \"Generate a budget for opportunity PA-25-147. Use the research team to collect information about opportunity PA-25-147. Use the budget analysis team to generate a budget from the study complexity provided by the research team. And then use the documents team to write the budget team's output to a new file.\"\n",
    "\n",
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Provide a list of the ten most recent University of Utah NIH-funded projects\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 30},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
