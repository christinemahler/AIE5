{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47eTBHYNP4g1"
      },
      "source": [
        "# Introduction to LCEL and LangGraph: LangChain Powered RAG\n",
        "\n",
        "In the following notebook we're going to focus on learning how to navigate and build useful applications using LangChain, specifically LCEL, and how to integrate different APIs together into a coherent RAG application!\n",
        "\n",
        "In the notebook, you'll complete the following Tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables  \n",
        "  3. Initialize a Simple Chain using LCEL\n",
        "  4. Implement Naive RAG using LCEL\n",
        "  5. Implement Simple RAG using LCEL\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Install LangGraph\n",
        "  2. Understanding States and Nodes\n",
        "  3. Building a Basic Graph\n",
        "  4. Implementing a Simple RAG Graph\n",
        "  5. Extending the Graph with Complex Flows\n",
        "\n",
        "Let's get started!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ayVXHXHRE_t"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHd6POM0JFN"
      },
      "source": [
        "## Installing Required Libraries\n",
        "\n",
        "One of the [key features](https://blog.langchain.dev/langchain-v02-leap-to-stability/) of LangChain v0.2.0 is the compartmentalization of the various LangChain ecosystem packages and added stability.\n",
        "\n",
        "Instead of one all encompassing Python package - LangChain has a `core` package and a number of additional supplementary packages.\n",
        "\n",
        "We'll start by grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCC2AR-Q0m0x",
        "outputId": "cbd49ab6-f2fb-420c-e64c-e656ad21524e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain==0.3.15 langchain-core==0.3.31 langchain-community==0.3.15 langchain-openai==0.3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ELHQjQ1PYs"
      },
      "source": [
        "Now we can get our Qdrant dependencies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76XeYI9P1OXO",
        "outputId": "7fde097a-b482-47b5-be14-05c48c695841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-qdrant==0.2.0 qdrant-client==1.13.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iesey9OGCKJx"
      },
      "source": [
        "Let's finally get `tiktoken` and `pymupdf` so we can leverage them later on!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5qIUrFuENrS",
        "outputId": "ea9d4e53-7018-4fd9-dab1-4223772b9bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU tiktoken pymupdf==1.25.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6wTp9C5qbY"
      },
      "source": [
        "## Set Environment Variables\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs - so we'll set our `OPENAI_API_KEY` `env` variable here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pKAfycq73wE",
        "outputId": "0b5702c2-028b-4bf4-ae8a-fffe243574a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_xp54wIA56_"
      },
      "source": [
        "## Initialize a Simple Chain using LCEL\n",
        "\n",
        "The first thing we'll do is familiarize ourselves with LCEL and the specific ins and outs of how we can use it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyGdhbS6SkD1"
      },
      "source": [
        "### LLM Orchestration Tool (LangChain)\n",
        "\n",
        "Let's dive right into [LangChain](https://www.langchain.com/)!\n",
        "\n",
        "The first thing we want to do is create an object that lets us access OpenAI's `gpt-4o` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Uj6SorxMj8e"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmiieEh_Ye-"
      },
      "source": [
        "####‚ùì Question #1:\n",
        "\n",
        "What other models could we use, and how would the above code change?\n",
        "\n",
        "**In addition to one of the \"flagship\" models, we could also use GPT-4o Realtime, GPT-4o Audio, GPT-3.5 Turbo, etc. We simply pass in a different model name to the `ChatOpenAI` constructor.**\n",
        "\n",
        "> HINT: Check out [this page](https://platform.openai.com/docs/models) to find the answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nU8SlHfH41T"
      },
      "source": [
        "### Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcMKLZWBVYm7"
      },
      "source": [
        "Now, we'll set up a prompt template - more specifically a `ChatPromptTemplate`. This will let us build a prompt we can modify when we call our LLM!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z770j4zPS3o5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"You are a legendary and mythical Wizard. You speak in riddles and make obscure and pun-filled references to exotic cheeses.\"\n",
        "human_template = \"{content}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGku_c2VVyd_"
      },
      "source": [
        "### Our First Chain\n",
        "\n",
        "Now we can set up our first chain!\n",
        "\n",
        "A chain is simply two components that feed directly into eachother in a sequential fashion!\n",
        "\n",
        "You'll notice that we're using the pipe operator `|` to connect our `chat_prompt` to our `llm`.\n",
        "\n",
        "This is a simplified method of creating chains and it leverages the LangChain Expression Language, or LCEL.\n",
        "\n",
        "You can read more about it [here](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel), but there a few features we should be aware of out of the box (taken directly from LangChain's documentation linked above):\n",
        "\n",
        "- **Async, Batch, and Streaming Support** Any chain constructed this way will automatically have full sync, async, batch, and streaming support. This makes it easy to prototype a chain in a Jupyter notebook using the sync interface, and then expose it as an async streaming interface.\n",
        "\n",
        "- **Fallbacks** The non-determinism of LLMs makes it important to be able to handle errors gracefully. With LCEL you can easily attach fallbacks to any chain.\n",
        "\n",
        "- **Parallelism** Since LLM applications involve (sometimes long) API calls, it often becomes important to run things in parallel. With LCEL syntax, any components that can be run in parallel automatically are.\n",
        "\n",
        "In the following code cell we have two components:\n",
        "\n",
        "- `chat_prompt`, which is a formattable `ChatPromptTemplate` that contains a system message and a human message.\n",
        "- `openai_chat_model`, which is a LangChain Runnable wrapped OpenAI client.\n",
        "\n",
        "We'd like to be able to pass our own `content` (as found in our `human_template`) and then have the resulting message pair sent to our model and responded to!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RcJyqOiwVt04"
      },
      "outputs": [],
      "source": [
        "chain = chat_prompt | openai_chat_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV_kHCjlL_01"
      },
      "source": [
        "Notice the pattern here:\n",
        "\n",
        "We invoke our chain with the `dict` `{\"content\" : \"Hello world!\"}`.\n",
        "\n",
        "It enters our chain:\n",
        "\n",
        "`{\"content\" : \"Hello world!\"}` -> `invoke()` -> `chat_prompt`\n",
        "\n",
        "Our `chat_prompt` returns a `PromptValue`, which is the formatted prompt. We then \"pipe\" the output of our `chat_prompt` into our `llm`.\n",
        "\n",
        "`PromptValue` -> `|` -> `llm`\n",
        "\n",
        "Our `llm` then takes the list of messages and provides an output which is return as a `str`!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cqr2QuMtIjn",
        "outputId": "acc3f8bc-106a-4fd6-9b4e-6caddc0a94ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Ah, greetings to thee, inquisitive soul,  \\nIn a realm where thoughts like curds do roll.  \\nWhat curious quest doth thou embark,  \\nIn this grand dairy of knowledge, shall we embark?  \\nCast thine inquiries like a fine Camembert,  \\nAnd I shall age the answers with utmost care. üßô\\u200d‚ôÇÔ∏èüßÄ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 38, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None} id='run-2187f81f-582d-45e2-932d-f15649c7c9dd-0' usage_metadata={'input_tokens': 38, 'output_tokens': 76, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"content\": \"Hello world!\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2znL48ECNteM"
      },
      "source": [
        "Let's try it out with a different prompt!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjiTNeYXUCAB",
        "outputId": "b5d2bb5b-487f-4a3e-8673-5f31987a56f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Ah, seeker of the serpentine syntax, lend me thine ear as I conjure forth kernels of wisdom wrapped in riddle and jest, akin to a wheel of Roquefort nestled in the crevice of a cavern.\\n\\nFirst, ponder this curdled conundrum: **What is both a code and a cheddar?**  \\n**Answer**: The answer you seek, dear apprentice, is practice! For like the aging of a good Gruy√®re, skill develops slowly over time, layered with effort and consistency. Commit your thoughts to parchment, and let no snippet languish in obscurity!\\n\\nNext, to dance with the Pythons of your craft, one must embrace the ties that bind: **What is a language that plays with strings and is sharper than a fine Parmigiano?**  \\n**Answer**: Community! Engage with realms like GitHub or the forums of Stack Overflow! Connecting with fellow curd craftsmen will enrich your mind like a good Brie at a banquet, and the feedback shall be the rennet that binds the curds of camaraderie!\\n\\nLastly, think beyond the surface of the Camembert‚Äî**What grows when left in darkness but shines when you share its secrets?**  \\n**Answer**: Knowledge! Document thine own journey through the land of Python, sharing what you learn. For a true wizard knows that each line scribed is like a slice of Swiss, with holes holding the space for others to journey through!\\n\\nSo, my aspiring conjurer of code, may thy code be as flavorful as a fine feta and thy challenges as crumbly as a blue cheese! Now, go forth and wield the power of Python with wisdom, humor, and perhaps a platter of fine cheeses at your side! üßÄ‚ú®', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 360, 'prompt_tokens': 50, 'total_tokens': 410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-2294329a-7ae8-4015-8f0e-3bb3c42490c0-0', usage_metadata={'input_tokens': 50, 'output_tokens': 360, 'total_tokens': 410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"content\" : \"Could I please have some advice on how to become a better Python Programmer?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THcMz8YAWsjP"
      },
      "source": [
        "Notice how we specifically referenced our `content` format option!\n",
        "\n",
        "Now that we have the basics set up - let's see what we mean by \"Retrieval Augmented\" Generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7o8aXbhRAPe"
      },
      "source": [
        "## Naive RAG - Manually adding context through the Prompt Template\n",
        "\n",
        "Let's look at how our model performs at a simple task - defining what LangChain is!\n",
        "\n",
        "We'll redo some of our previous work to change the `system_template` to be less...verbose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu_Uox_pPKaf",
        "outputId": "57ca2111-c0c6-47c3-968d-978828901ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='As of my last update in October 2023, \"LangGraph\" does not appear to be a widely recognized term in the fields of language processing, graph theory, or related technologies. However, it is possible that it could refer to a specific concept, framework, or tool developed for natural language processing (NLP) and graph-based data representation, particularly in the context of language models, knowledge graphs, or similar areas.\\n\\nIf you are referring to a new tool or framework that has emerged since my last update, I\\'d recommend checking the latest literature, official documentation, or community discussions to get the most accurate and up-to-date information. If you have more context or a specific use case in mind, feel free to provide that, and I would be happy to help you further!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 158, 'prompt_tokens': 22, 'total_tokens': 180, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-22e3a368-acd1-4621-8dbe-706fe8a58630-0' usage_metadata={'input_tokens': 22, 'output_tokens': 158, 'total_tokens': 180, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "system_template = \"You are a helpful assistant.\"\n",
        "human_template = \"{content}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template)\n",
        "])\n",
        "\n",
        "chat_chain = chat_prompt | openai_chat_model ### LCEL Chain!\n",
        "\n",
        "print(chat_chain.invoke({\"content\" : \"Please define LangGraph.\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18KXqGI4XbMb"
      },
      "source": [
        "Well, that's not very good - is it!\n",
        "\n",
        "The issue at play here is that our model was not trained on the idea of \"LangChain\", and so it's left with nothing but a guess - definitely not what we want the answer to be!\n",
        "\n",
        "Let's ask another simple LangChain question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRG5LwYoXnsr",
        "outputId": "11185027-a453-43d9-895d-19c654524081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"LangChain Expression Language (LECL) is a specialized language designed to simplify the manipulation and querying of data within the LangChain framework. It's primarily aimed at enhancing the functionality of Language Models (LLMs) by enabling users to perform complex data retrieval and manipulation tasks more intuitively.\\n\\nLECL is used for:\\n\\n1. **Data Retrieval**: It allows users to extract specific information from datasets or documents using concise expressions.\\n2. **Data Transformation**: Users can apply transformations or computations on the data, making it easier to format or modify the information as needed.\\n3. **Integration with Language Models**: LECL can enhance LLMs by allowing them to understand and execute more complex queries, making them more powerful in data-driven applications.\\n\\nOverall, LECL provides a flexible and expressive way to work with data in conjunction with language models, streamlining the process of querying and manipulating data in a way that is both powerful and user-friendly. This capability is particularly useful in applications that require a combination of natural language processing and data handling.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 27, 'total_tokens': 236, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-04b30576-6a92-4446-afe4-ae5f0efd1588-0' usage_metadata={'input_tokens': 27, 'output_tokens': 209, 'total_tokens': 236, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "print(chat_chain.invoke({\"content\" : \"What is LangChain Expression Language (LECL)?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63pr0fgYXxC3"
      },
      "source": [
        "While it provides a confident response, that response is entirely ficticious! Not a great look, OpenAI!\n",
        "\n",
        "However, let's see what happens when we rework our prompts - and we add the content from the docs to our prompt as context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgr25HjgYHwh",
        "outputId": "40e5e551-345e-4c43-c47b-2269d51a0cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='LangChain Expression Language (LCEL) is a declarative way to compose chains together in a simplified manner. It offers several benefits, including automatic support for sync, async, batch, and streaming interfaces, the ability to handle errors gracefully with fallbacks, built-in parallelism for components that can run concurrently, and seamless integration with LangSmith for logging and tracing the steps in complex chains for better observability and debuggability.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 282, 'total_tokens': 369, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None} id='run-a1ce14b7-226c-4de9-bdba-8fc545a01816-0' usage_metadata={'input_tokens': 282, 'output_tokens': 87, 'total_tokens': 369, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "CONTEXT = \"\"\"\n",
        "LangChain Expression Language or LCEL is a declarative way to easily compose chains together. There are several benefits to writing chains in this manner (as opposed to writing normal code):\n",
        "\n",
        "Async, Batch, and Streaming Support Any chain constructed this way will automatically have full sync, async, batch, and streaming support. This makes it easy to prototype a chain in a Jupyter notebook using the sync interface, and then expose it as an async streaming interface.\n",
        "\n",
        "Fallbacks The non-determinism of LLMs makes it important to be able to handle errors gracefully. With LCEL you can easily attach fallbacks to any chain.\n",
        "\n",
        "Parallelism Since LLM applications involve (sometimes long) API calls, it often becomes important to run things in parallel. With LCEL syntax, any components that can be run in parallel automatically are.\n",
        "\n",
        "Seamless LangSmith Tracing Integration As your chains get more and more complex, it becomes increasingly important to understand what exactly is happening at every step. With LCEL, all steps are automatically logged to LangSmith for maximal observability and debuggability.\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])\n",
        "\n",
        "chat_chain = chat_prompt | openai_chat_model\n",
        "\n",
        "print(chat_chain.invoke({\"query\" : \"What is LangChain Expression Language?\", \"context\" : CONTEXT}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppQdtCedY7C4"
      },
      "source": [
        "You'll notice that the response is much better this time. Not only does it answer the question well - but there's no trace of confabulation (hallucination) at all!\n",
        "\n",
        "> NOTE: While RAG is an effective strategy to *help* ground LLMs, it is not nearly 100% effective. You will still need to ensure your responses are factual through some other processes\n",
        "\n",
        "That, in essence, is the idea of RAG. We provide the model with context to answer our queries - and rely on it to translate the potentially lengthy and difficult to parse context into a natural language answer!\n",
        "\n",
        "However, manually providing context is not scalable - and doesn't really offer any benefit.\n",
        "\n",
        "Enter: Retrieval Pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFmdARsVBJUq"
      },
      "source": [
        "## Task #4: Implement Naive RAG using LCEL\n",
        "\n",
        "Now we can make a naive RAG application that will help us bridge the gap between our Pythonic implementation and a fully LangChain powered solution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AozVoEZveK"
      },
      "source": [
        "## Putting the R in RAG: Retrieval 101\n",
        "\n",
        "In order to make our RAG system useful, we need a way to provide context that is most likely to answer our user's query to the LLM as additional context.\n",
        "\n",
        "Let's tackle an immediate problem first: The Context Window.\n",
        "\n",
        "All (most) LLMs have a limited context window which is typically measured in tokens. This window is an upper bound of how much stuff we can stuff in the model's input at a time.\n",
        "\n",
        "Let's say we want to work off of a relatively large piece of source data - like the Ultimate Hitchhiker's Guide to the Galaxy. All 898 pages of it!\n",
        "\n",
        "> NOTE: It is recommended you do not run the following cells, they are purely for demonstrative purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PbXBxffibeyp"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\n",
        "EVERY HITCHHIKER'S GUIDE BOOK\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZvgFuaXcHFT"
      },
      "source": [
        "We can leverage our tokenizer to count the number of tokens for us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HaKPOdSjbifn"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtDiSMxpE4Xi",
        "outputId": "886fd517-9128-45ca-9fbd-5152ae7f146b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(enc.encode(context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oUuZpAicLdm"
      },
      "source": [
        "The full set comes in at a whopping *636,144* tokens.\n",
        "\n",
        "So, we have too much context. What can we do?\n",
        "\n",
        "Well, the first thing that might enter your mind is: \"Use a model with more context window\", and we could definitely do that! However, even `gpt-4-128k` wouldn't be able to fit that whole text in the context window at once.\n",
        "\n",
        "So, we can try splitting our document up into little pieces - that way, we can avoid providing too much context.\n",
        "\n",
        "We have another problem now.\n",
        "\n",
        "If we split our document up into little pieces, and we can't put all of them in the prompt. How do we decide which to include in the prompt?!\n",
        "\n",
        "> NOTE: Content splitting/chunking strategies are an active area of research and iterative developement. There is no \"one size fits all\" approach to chunking/splitting at this moment. Use your best judgement to determine chunking strategies!\n",
        "\n",
        "In order to conceptualize the following processes - let's create a toy context set!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPCiOPwUfbqn"
      },
      "source": [
        "### TextSplitting aka Chunking\n",
        "\n",
        "We'll use the `RecursiveCharacterTextSplitter` to create our toy example.\n",
        "\n",
        "It will split based on the following rules:\n",
        "\n",
        "- Each chunk has a maximum size of 100 tokens\n",
        "- It will try and split first on the `\\n\\n` character, then on the `\\n`, then on the `<SPACE>` character, and finally it will split on individual tokens.\n",
        "\n",
        "Let's implement it and see the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nLW9AfDKfVHn"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nPYPBe2ngT9N"
      },
      "outputs": [],
      "source": [
        "chunks = text_splitter.split_text(CONTEXT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RGVlTihaQX",
        "outputId": "7ab8ae25-3b7f-4961-8d4d-9703580927d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTYny2xchS_Z",
        "outputId": "bbce26a0-5400-4ea7-bf02-3260de30137f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain Expression Language or LCEL is a declarative way to easily compose chains together. There are several benefits to writing chains in this manner (as opposed to writing normal code):\n",
            "\n",
            "Async, Batch, and Streaming Support Any chain constructed this way will automatically have full sync, async, batch, and streaming support. This makes it easy to prototype a chain in a Jupyter notebook using the sync interface, and then expose it as an async streaming interface.\n",
            "----\n",
            "Fallbacks The non-determinism of LLMs makes it important to be able to handle errors gracefully. With LCEL you can easily attach fallbacks to any chain.\n",
            "\n",
            "Parallelism Since LLM applications involve (sometimes long) API calls, it often becomes important to run things in parallel. With LCEL syntax, any components that can be run in parallel automatically are.\n",
            "----\n",
            "Seamless LangSmith Tracing Integration As your chains get more and more complex, it becomes increasingly important to understand what exactly is happening at every step. With LCEL, all steps are automatically logged to LangSmith for maximal observability and debuggability.\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in chunks:\n",
        "  print(chunk)\n",
        "  print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98hOgu5Yhefv"
      },
      "source": [
        "As is shown in our result, we've split each section into 100 token chunks - cleanly separated by `\\n\\n` characters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PTiJ2utMpqq"
      },
      "source": [
        "####üèóÔ∏è Activity #1:\n",
        "\n",
        "While there's nothing specifically wrong with the chunking method used above - it is a naive approach that is not sensitive to specific data formats.\n",
        "\n",
        "Brainstorm some ideas that would split large single documents into smaller documents.\n",
        "\n",
        "1. Identify separate sections of the document using text formatting, and split by section.\n",
        "2. Split by paragraphs. \n",
        "3. Split by sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj18Rjafhp7d"
      },
      "source": [
        "## Embeddings and Dense Vector Search\n",
        "\n",
        "Now that we have our individual chunks, we need a system to correctly select the relevant pieces of information to answer our query.\n",
        "\n",
        "This sounds like a perfect job for embeddings!\n",
        "\n",
        "We'll be using OpenAI's `text-embedding-3` model as our embedding model today!\n",
        "\n",
        "Let's load it up through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "quNjOLWspOVN"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsGZ92hm9IeX"
      },
      "source": [
        "####‚ùì Question #2:\n",
        "\n",
        "What is the embedding dimension, given that we're using `text-embedding-3-small`?\n",
        "\n",
        "You will need to fill the next cell out correctly with your embedding dimension for the rest of the notebook to run.\n",
        "\n",
        "> HINT: Check out the [docs](https://platform.openai.com/docs/guides/embeddings) to help you answer this question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uQu1rCHw-YGF"
      },
      "outputs": [],
      "source": [
        "embedding_dim =  1536"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByK-zb0FsnqR"
      },
      "source": [
        "### Using A Vector Database - Intoduction to Qdrant\n",
        "\n",
        "Up to this point, we've been using a dictionary to hold our embeddings - typically, we'll want to use a more robust strategy.\n",
        "\n",
        "In this bootcamp - we'll be focusing on leveraging [Qdrant's vector database](https://qdrant.tech/qdrant-vector-database/).\n",
        "\n",
        "Let's take a look at how we set-up Qdrant!\n",
        "\n",
        "> NOTE: We'll be spending a lot of time learning about Qdrant throughout the remainder of our time together - but for an initial primer, please check out [this resource](https://qdrant.tech/articles/what-is-a-vector-database/)\n",
        "\n",
        "We are going to be using an \"in-memory\" Qdrant client, which means that our vectors will be held in our system's memory (RAM) - this is useful for prototyping and developement at smaller scales - but would need to be modified when moving to production. Luckily for us, this modification is trivial!\n",
        "\n",
        "> NOTE: While LangChain uses the terminology \"VectorStore\" (also known as a Vector Library), Qdrant is a \"Vector Database\" - more info. on that [here](https://weaviate.io/blog/vector-library-vs-vector-database)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EqSFeTNVhHRH"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax_Oz0P0mz8i"
      },
      "source": [
        "Next, we need to create a collection - a collection is a specific...collection of vectors within the Qdrant client.\n",
        "\n",
        "These are useful as they allow us to create multiple different \"warehouses\" in a single client, which can be leveraged for personalization and more!\n",
        "\n",
        "Also notice that we define what our vector shapes are (embedding dim) as well as our desired distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urH-37OYh6Ca",
        "outputId": "f1866617-a63f-4eac-d7af-49f1b9ccebb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"lcel_doc_v1\",\n",
        "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCqGyuDp-4gQ"
      },
      "source": [
        "Now we can assemble our vector database! Notice that we provide our client, our created collection, and our embedding model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pGDWp-xA-26d"
      },
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"lcel_doc_v1\",\n",
        "    embedding=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hX7erW-S1f"
      },
      "source": [
        "Now that we have our vector database set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_-qHPtPh-SYb"
      },
      "outputs": [],
      "source": [
        "_ = vector_store.add_texts(texts=chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPJexL1kuw45"
      },
      "source": [
        "### Creating a Retriever\n",
        "\n",
        "Now that we have an idea of how we're getting our most relevant information - let's see how we could create a pipeline that would automatically extract the closest chunk to our query and use it as context for our prompt!\n",
        "\n",
        "This will involve a popular LangChain interace known as `as_retriever`!\n",
        "\n",
        "> NOTE: We can still specify how many documents we wish to retrieve per vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tnLpo26pu8-1"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4CZ4tKBSeA"
      },
      "source": [
        "## Bringing it All Together\n",
        "\n",
        "Now that we have our Retriever, our promt Augmentation, and our Generator - we're ready to create a simple RAG chain using LCEL!\n",
        "\n",
        "This chain does the following things:\n",
        "\n",
        "1. It takes in some `str` and passes it to two different LCEL Runnables:\n",
        "  - `retriever`, which takes the string and calls `retrieve` on it - passing the output (formatted as a list) to the `dict` under the key `context`\n",
        "  - `RunnablePassthrough()` which simply propogates the `str` to the `dict` under the key `query`.\n",
        "2. It chains the `dict` to format the `chat_prompt` which expects both a `query` and `context`\n",
        "3. It chains the resulting message to the LLM, and calls it - returning a full response\n",
        "4. That response is chained to the `StrOutputParser()` which converts the response blob into a `str` containing the content of the response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Pi8sgqhsBeV_"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "simple_rag  = (\n",
        "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
        "    | chat_prompt\n",
        "    | openai_chat_model\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "XpY2CiSGBiGX",
        "outputId": "810727f7-843a-4c49-867b-9067fdbda4d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LCEL, or LangChain Expression Language, is a declarative way to easily compose chains together. It offers several benefits, including support for async, batch, and streaming operations, allowing easy prototyping in a Jupyter notebook. Additionally, LCEL facilitates error handling with fallbacks for non-determinism in LLMs and enables parallel execution of components that can run concurrently, which is useful given that LLM applications often involve long API calls.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_rag.invoke(\"What is LCEL?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD2URVX3O3XJ"
      },
      "source": [
        "####‚ùì Question #3:\n",
        "\n",
        "What does LCEL do that makes it more reliable at scale?\n",
        "\n",
        "> HINT: Use your newly created `simple_rag` to help you answer this question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LCEL enhances reliability at scale by allowing for fallbacks, which help handle errors gracefully due to the non-determinism of LLMs. Additionally, it supports parallelism, enabling the execution of components that can run concurrently, which is particularly beneficial for managing long API calls in LLM applications. This combination of features contributes to the robustness of chains constructed using LCEL.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_rag.invoke(\"What does LCEL do that makes it more reliable at scale?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsujAkpRWpJ"
      },
      "source": [
        "### A Note On Runnables\n",
        "\n",
        "# Understanding LangChain Runnables and LCEL\n",
        "\n",
        "In LangChain, a Runnable is like a LEGO brick in your AI application - it's a standardized component that can be easily connected with other components. The real power of Runnables comes from their ability to be combined in flexible ways using LCEL (LangChain Expression Language).\n",
        "\n",
        "## Key Features of Runnables\n",
        "\n",
        "### 1. Universal Interface\n",
        "Every Runnable in LangChain follows the same pattern:\n",
        "- Takes an input\n",
        "- Performs some operation\n",
        "- Returns an output\n",
        "\n",
        "This consistency means you can treat different components (like models, retrievers, or parsers) in the same way.\n",
        "\n",
        "### 2. Built-in Parallelization\n",
        "Runnables come with methods for handling multiple inputs efficiently:\n",
        "```python\n",
        "# Process inputs in parallel, maintain order\n",
        "results = chain.batch([input1, input2, input3])\n",
        "\n",
        "# Process inputs as they complete\n",
        "for result in chain.batch_as_completed([input1, input2, input3]):\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "### 3. Streaming Support\n",
        "Perfect for responsive applications:\n",
        "```python\n",
        "# Stream outputs as they're generated\n",
        "for chunk in chain.stream({\"query\": \"Tell me a story\"}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "```\n",
        "\n",
        "### 4. Easy Composition\n",
        "The `|` operator makes building pipelines intuitive:\n",
        "```python\n",
        "# Create a basic RAG chain\n",
        "rag_chain = retriever | prompt | model | output_parser\n",
        "```\n",
        "\n",
        "## Common Types of Runnables\n",
        "\n",
        "- **Language Models**: Like our `ChatOpenAI` instance\n",
        "- **Prompt Templates**: Format inputs consistently\n",
        "- **Retrievers**: Get relevant context from a vector store\n",
        "- **Output Parsers**: Structure model outputs\n",
        "- **LangGraph Nodes**: Individual components in our graph\n",
        "\n",
        "Think of Runnables as the building blocks of your LLM application. Just like how you can combine LEGO bricks in countless ways, you can mix and match Runnables to create increasingly sophisticated applications!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIbX3_htQGlS"
      },
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaVlJiilDzwM"
      },
      "source": [
        "## LangGraph Based RAG\n",
        "\n",
        "Now that we have a reasonable grasp of LCEL and the idea of Runnables - let's see how we can use LangGraph to build the same system!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77-NKo1EowG"
      },
      "source": [
        "### Primer: What is LangGraph?\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "#### Why Cycles?\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "#### Why LangGraph?\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!\n",
        "\n",
        "> NOTE: We're going to focus on building a simple DAG for today's assignment as an introduction to LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VJy-ASfAFRRE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfLCnMXNE_Qc"
      },
      "source": [
        "### Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "> coordinated multi-actor and stateful applications\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "However, in our example here, we're focusing on a simpler `State` object:\n",
        "\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    response: str\n",
        "```\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. **We initialize our state object**:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "2. **Our user submits a query to our application.**  \n",
        "   We store the user's question in `state[\"question\"]`. Now we have:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **We pass our state object to an Agent node** which is able to read the current state. It will use the value of `state[\"question\"]` as input and might retrieve some context documents related to the question. It then generates a response which it stores in `state[\"response\"]`. For example:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [Document(page_content=\"...some data...\")],\n",
        "       \"response\": \"The Eiffel Tower is about 324 meters tall...\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "That's it! The important part is that we have a consistent object (`State`) that's passed around, holding the crucial information as we go from one node to the next. This ensures our application has a single source of truth about what has happened so far and what is happening now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kxczzsfVFNWT"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6xFY0_HoXG"
      },
      "source": [
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL Runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keL9O1drInw1"
      },
      "source": [
        "### Building Nodes\n",
        "\n",
        "We're going to need two nodes:\n",
        "\n",
        "A node for retrieval, and a node for generation.\n",
        "\n",
        "Let's start with our `retrieve` node!\n",
        "\n",
        "Notice how we do not need to update the state object in the node, but can instead return a modification directly to our state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "05qhncktIwK_"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gZktSLAJL5Z"
      },
      "source": [
        "Next, let's create our `generate` node - which will leverage some LCEL!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XiL2isC8JS0l"
      },
      "outputs": [],
      "source": [
        "def generate(state: State) -> State:\n",
        "  generation_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generation_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtriMEcJxeR"
      },
      "source": [
        "Now we can start defining our graph!\n",
        "\n",
        "Think of the graph's state as a blank canvas that we can add nodes and edges to.\n",
        "\n",
        "Every graph starts with two special nodes - START and END - the act as the entry and exit point to the other nodes in the graphs.  \n",
        "\n",
        "All valid graphs must start at the START node and end at the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ia9IWM9AJ4bx"
      },
      "outputs": [],
      "source": [
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kro8bQEL2Yj"
      },
      "source": [
        "Now we can add a sequence to our \"canvas\" (graph) - this can be done by providing a list of nodes, the will automatically have edges that connect the i-th element to the i+1-th element in the list. The final element will be added to the END node unless otherwise specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OSfDMlXUL2kh"
      },
      "outputs": [],
      "source": [
        "graph_builder = graph_builder.add_sequence([retrieve, generate])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g79NZf5VL4en"
      },
      "source": [
        "Next, let's connect our START node to our `retrieve` node by adding an edge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "w1kTJKGNL4qA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x115464440>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"retrieve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiVyt8-L6_5"
      },
      "source": [
        "Finally we can compile our graph! This will do basic verification to ensure that the Runnables have the correct inputs/outputs and can be matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TM4My6geL7FW"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvoQcfCP3xI"
      },
      "source": [
        "Finally, we can visualize our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "RgKu1O3QLKF6",
        "outputId": "39566d40-27e6-44e2-894c-68420030653d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        graph.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRCjvvyP8DA"
      },
      "source": [
        "Let's take it for a spin!\n",
        "\n",
        "We invoke our graph like we do any other Runnable in LCEL!\n",
        "\n",
        "> NOTE: That's right, even a compiled graph is a Runnable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mSbsRLurKOKd",
        "outputId": "114185f3-4b98-4c66-96cd-65f4e4e3ef1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LCEL, or LangChain Expression Language, works as a declarative way to compose chains together. It provides several advantages: \\n\\n1. **Async, Batch, and Streaming Support**: Any chain composed using LCEL automatically has full synchronous, asynchronous, batch, and streaming support, which facilitates prototyping in environments like Jupyter notebooks and later exposing them as async streaming interfaces.\\n\\n2. **Fallbacks**: Given the non-determinism of language models, LCEL allows for easy attachment of fallbacks to any chain, enabling graceful error handling.\\n\\n3. **Parallelism**: LCEL syntax enables components that can be run in parallel to do so automatically, which is beneficial in LLM applications due to often lengthy API calls. \\n\\nOverall, LCEL simplifies the process of building complex chains in an efficient and manageable way.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"How does LCEL work?\"})\n",
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_jEmE_rKwED",
        "outputId": "c5fac807-2a24-4cf9-8cca-105def13e3d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"Who is Batman?\"})\n",
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LRYXvvRjOp"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "LangGraph's graph-based approach lets us visualize and manage complex flows naturally. How could we extend our current implementation to handle edge cases? For example:\n",
        "- What if the retriever finds no relevant context?  \n",
        "- What if the response needs fact-checking?\n",
        "Consider how you would modify the graph to handle these scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'LCEL, or LangChain Expression Language, is a declarative framework that allows users to easily compose chains together. It provides several benefits compared to writing normal code, including:\\n\\n1. **Async, Batch, and Streaming Support**: Any chain constructed using LCEL automatically supports synchronous, asynchronous, batch, and streaming interfaces. This feature facilitates quick prototyping in environments like Jupyter notebooks and allows for later exposure as an async streaming interface.\\n\\n2. **Fallbacks**: Given the non-determinism of large language models (LLMs), LCEL lets users attach fallbacks to any chain, enabling graceful error handling.\\n\\n3. **Parallelism**: LLM applications may include lengthy API calls, making it essential to run tasks in parallel. LCEL syntax allows components that can be executed in parallel to do so automatically.\\n\\nOverall, LCEL simplifies the process of building and managing chains in a more efficient and flexible manner.'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Any, Dict, Literal\n",
        "from langgraph.graph import END\n",
        "\n",
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  if len(retrieved_docs) == 0:\n",
        "    return {\"context\" : []}\n",
        "  else:\n",
        "    return ({\"context\" : retrieved_docs})\n",
        "  \n",
        "def generate(state: State) -> State:\n",
        "  generation_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generation_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}\n",
        "\n",
        "def no_context(state: State) -> State:\n",
        "  return {\"response\" : \"I don't know the answer to that question.\"}\n",
        "\n",
        "def evaluate_context(state: State) -> Literal['no_context', 'generate']:\n",
        "    context = state['context']\n",
        "\n",
        "    if len(context) == 0:\n",
        "        return 'no_context'\n",
        "    return 'generate'\n",
        "\n",
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder = graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder = graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder = graph_builder.add_node(\"no_context\", no_context)\n",
        "graph_builder = graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder = graph_builder.add_conditional_edges(\"retrieve\", evaluate_context)\n",
        "graph_builder = graph_builder.add_edge(\"generate\", END)\n",
        "graph_builder = graph_builder.add_edge(\"no_context\", END)\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        graph.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "question = \"How does LCEL work?\"\n",
        "\n",
        "response = graph.invoke({\"question\" : question})\n",
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAGwCAIAAAB3oLZcAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU9ffB/CTAQGSQNgbFUHBgYiCgigqOEBEce9R/al119mqtdZZt7ZaF1pnrVZxDxRxsEREqCIiKEtENgEC2cnzx/WhVAEVAyc39/v+wxeE5PKBmA/njpxDUyqVCAAAqIeOOwAAAOAB9QcAoCioPwAARUH9AQAoCuoPAEBRUH8AAIpi4g4A1F1pgVhQJq+ulImqFRKRAnecz6KtQ6czkB6XqafPsLDToTNouBMBdUSD6/5AnfIyhBnPqjKTq0xttMVChR6XqW+kRSNJjWjr0suLpNWVMlGV8l1WtY2DXquObCcPfS0tkvwAoFlA/YEPFeaIYq6WcA2ZRhbarTqweabauBN9rZzU6ozkqrevhI6dOR4DjHDHAeoC6g/8x4PQondZIq9AY9s2erizqF7cjZLEu/z+E83tO3JwZwH4Qf2B9yQixektOT4jTFu2Y+PO0oSkEsX9c0X6xlowDARQfwAhhGQSxeHVmWOX2ekbaeHO0hzibpTQGTT3/tCAlAb1B5BQID+xMWvGxta4gzSrh9eLBXy53zhz3EEANnDdH0B/bs6Z8EML3CmaW/cAEx09RuK9MtxBADZQf1R3568C/6kWelwqXgHqPdSEXyjNTavGHQTgAfVHaVkpVdUVcit7XdxBsHHpafDgQjHuFAAPqD9Ki7la4hVojDsFTsaWLBNr7ZePK3EHARhA/VHX66eCFs56xlYs3EEw8w4ySU+C+qMiqD/qSntSaW6r0zzfSy6XJyUl4Xp4w/T0mdUV8oIcURNtH6gtqD/qykyuatWhma5wXrdu3caNG3E9/JNadWBnJlc13faBeoL6o6ic1Oq2XbgMZjNNASAWixv3QOK61EY//DO1duEU5zXttwBqiIqXOwCEUFmhRIvVJH/8srOzN23alJycrK+v7+3t/f33369du/b27dsIoa5duyKELl++bGVllZSUFBISQuzStm/ffuHChc7Ozgih8PDw77//ftu2bSdOnHj+/PnkyZMLCgo+frhqM+sbMd+kCVW7TaD+oP4oqqpCxtZvkmd/3bp1WVlZixcvrqqqevz4MZ1O/+abbwoKCt6+fbt27VqEkImJCUIoLy9PLBZPnz6dTqf//fff8+fPv3Llio7O+2ORmzdvnjNnzrfffmtnZycSiT5+uGoxtekMBk0slLN0GSrfOFBbUH8UVVUuNzJvkpms8vLynJycgoODEUITJkxACNnZ2fF4vJKSEldX15q7+fv7BwQEEB+3a9du1qxZSUlJ3bt3J24ZPXp0YGBgzZ0/frjKsfUZVRVQf9QC9UdRdAZqogN/AQEBR48e3bJly/Tp042M6p1TgEaj3b179+TJk5mZmXp6egihkpKSmq96eHg0RbYG6LAZCjm8/51a4NQHRbF0GQK+rCm2PGfOnEWLFt26dSsoKOjs2bP13S0kJGTp0qXt2rXbsWPHwoULEUIKxb8z6ROF2JzKCiVNdDQAqC2oP4oi9vWaYss0Gm3cuHGXLl3y8fHZsmVLzfV6tecWEovFf/zxx9ChQxcvXuzq6tqxY8dPbrZJpyZSyJVioUKXA3u+1AL1R1EGJk01rx9xkQqbzZ41axZCKDU1FSGkq6tbUlJSM74TCoVisZg41YsQ4vP5H4z+PvDBw1VOUC7T7EleQZ1gtE9RLZzZN4/lew9R/VnU5cuXczic7t27R0VFIYSIjnNzc7t8+fLGjRtdXV319fV79erl4ODw119/GRsbCwSCgwcP0un0V69e1bfNjx+u2syZz6q4RvBaoBzGmjVrcGcAGNDptLwMoR6HqfJhYG5ublRU1M2bN4VC4bx583r37o0QcnBwKC8vv3nz5pMnT3g8noeHh5ubW3R09NmzZ7Ozs+fNm9eiRYvz58+PHz8+Ozs7PDx81KhRPB6vZpsfP1y1mR9eL2nXXd/AmBIzXYMaMNszdb2Iq6gsk3oMpPSMLwghuUx5ef/b4Lk2uIOA5gYDfupy7qZ/+MfMDj0M6pvrNDk5ee7cuR/fzuVyKyvrniJlwYIFxBV/TWr69Ol17imbm5sXFBR8fPuoUaNmz55d39Zir5W0bA8H/qgIRn+UlhJX8S5D6Du27vUuJBJJcfGXTQVqYGDAZjd5lRQVFUml0o9vl0qlWlp17MByOBx9ff06NyUUyE/9kj19vX0TxATqDuqP6q4fedcjyKTpTgSruYfXSwzNtdt24eIOAjCAC1+ozm+c+V/bcnCnwONZdLmoSg7dR1lQf1SnrUMPmmV1Zvsb3EGaW8YzwcvHlb1HmuEOArCBnV+AEELlJZKbfxSMXmKLO0gzSU+sfJUk8J9qiTsIwAlGfwAhhAyMtXuNMDmw/HV5sQR3liaXEF4G3Qdg9Af+QyJWhJ8q0Nahew021siVf18lCaKvFHfw1O/iV+9UNIA6oP7Ah148qoi5UtLBW9+yha6dU3PPvNIUqsplGc+qslOrGUzUY7CJPry7AyAE9QfqlRJXnp4oePtK6NKTR8wQwzFkMpjkOFrCYNAEfGlVhVxYKc/PFlVXyuw7cJw99M3sqL6qJ6gN6g80RC5TZr+oKi+WVlXIxUKFqErFc2QJBILc3FwnJyfVbpbDY8plSrY+g8PTMrNlmdpA64E6QP0BnJKSkn777bfDhw/jDgKoiBz7MgAAoHJQfwAAioL6AzgxGAxra2vcKQBFQf0BnORy+du3b3GnABQF9QdwotPpzTBBFgB1gvoDOCkUiqqqKtwpAEVB/QGc6HS6oaEh7hSAoqD+AE4KhaKsrAx3CkBRUH8AJwaDYWdnhzsFoCioP4CTXC7PyaHoXNMAO6g/AABFQf0BnOh0en1rsAHQ1KD+AE4KhaKiogJ3CkBRUH8AJxj9AYyg/gBOMPoDGEH9AQAoCuoP4MRgMCwtYcU1gAfUH8BJLpe/e/cOdwpAUVB/AACKgvoDODEYDBsbG9wpAEVB/QGc5HJ5bm4u7hSAoqD+AAAUBfUHcIIZXwBGUH8AJ5jxBWAE9QcAoCioP4ATLHQJMIL6AzjBQpcAI6g/AABFQf0BnGCdX4AR1B/ACdb5BRhB/QGcYMYXgBHUH8AJZnwBGEH9AQAoCuoP4ESj0QwNDXGnABQF9QdwUiqVZWVluFMAioL6AzjR6XRbW1vcKQBFQf0BnBQKxZs3b3CnABQF9QdwggmvAEZQfwAnmPAKYAT1B3Ci0+kmJia4UwCKoimVStwZAOWMHj26urqaRqOJxeLq6moej0ej0UQi0a1bt3BHAxTCxB0AUJGvr+/BgwdrPhUKhQghOAgImhns/AIMxo0b17Jly9q30Gi0fv364UsEqAjqD2DA4XAGDRrEYDBqbrG1tR05ciTWUIByoP4AHqNGjaq9wHn//v3hHAhoZlB/AA82mx0UFEQMAG1sbGDoB5of1B/AZuTIkcQAcODAgcbGxrjjAMqBM7/gPQFfVpIvkcua9UKogN5TIyMjvVyDM5Kbdc5ntj7DyFxbiwV//ikNrvsDqKxAEnWpuOituIUzp6pchjtOk6MzkIAvE1XL23TmeA2GA47UBfVHdRWl0kv78nzHW3ENtXBnaW5P75eKhDLf0Wa4gwA8YPBPaTKp4tSmnKFzW1Cw+xBCLj5GOmzmg9Ai3EEAHlB/lBZ3o9RrCKXHPi49jUoLJPwiCe4gAAOoP0p7+1pIzXFfbXQGveQd1B8VQf1RmxJB/RlZsAR8zT/hAz4G9UdpAr5MqcAdAjepWKGQ4w4BcID6AwBQFNQfAICioP4AABQF9QcAoCioPwAARUH9AQAoCuoPAEBRUH8AAIqC+gMAUBTUHwCAoqD+AAAUBfUHmpBAIEhLT234PhkZr4KG9ImKvtdcoQB4D+oPNKHpM8bcuHGp4fswmUwOh8tkwLIzoLnB/znQeEqlkkajNXAHiaShefSIh9vZtfzz1OUmSAfAJ8DoD3yBe/fD+/h2jYq6N2/BtH4Duv9xdD9CSCQS7dm7PXh4v0GDe836dmLE3VvEnceMCywrK7146e8+vl3HjAskbpw6bdTadT8cPxEydJhfQGBP4qt9fLs+Togj7lDn1l6kPu/j2/XqtQs1SY4eO9h/oGd5OR8hlJj0ePbcKQP8vcaMC9y85eeSkmIcvxtAPjD6A19s92+bp38z55up39pY2ykUipWrvsvPzxs/biqPZ5SU9Hjd+hUikTDAf8ian7YsWz7XtVOXkSPGa2lr1zw8Pj5WJBZtXL+zWlhta9NCKKw+eOg34ksNbM3Roe2t29cCBwUT97wdft3Hx8/AgJfw5NH3P8zv5xcQPHR0ZUX5+dDTi5bMCjl4WkuL6tO4gk+C+gNfLHjo6AED3o/m7t0Pf/os8fSpKyYmpgghP9+BQmH1+dDTAf5DnNq2YzKZxsYmHTu61n44g8n8ceVGXV1d4tNOLm41X3oQGVHf1gYNCt61+5f8/HcWFpbPnz/Ny8v9YfnPCKHf9mwdHDhs/rxlxBa6du0+eeqIrOwMR4e2zfgrAaQE9Qe+mJubR83HDx9GyWSycROCam6Ry+VsNqeBhzs7d6jpvg80sDXfvgP3H9gVfufGhPHf3Lp9zd7eoUOHTvn577KzM9++fVN7vxghJBBUft2PCCgB6g98MT1dvZqPy8pKjI1NdmzbX/sODGZD/690deruvoa3xuFw+vYZEH7nxuhRE+/euz3tm9nE/RFCkyfN6NWzb+2HmJtbNuonA9QC9Qe+Cperz+eXmZtbslisOu+gVCpVtbVBg4Kv37h04mSITCb18/VHCHE4XISQWCyys2v5FT8EoCg48wu+ipubh1wuv3zlXM0tQqGw5mNdHd0vOg/b8NbaOXdwaN3m5Kkjfr7+bDYbIWRjY2dubnHj5uWau8lkMqlU+tU/FqAEGP2Br9LPL+DK1dD9B3a/y89r4+j06lVaVPTdo0fO6ejoIIQ6dux8J+Lmn6ePcrn67du52Ns7fM3WiAHg7l83Dx48nPiURqPNmb149U9L58ybEjR4hEIuD7t1tV+/gBHDxzX9jw5ID+oPfBUtLa2tm/ceCvktIiLs6tVQGxu7oMEjmP9/7G/mjPmlpcUnTobwDAxnz170yfpreGsIIT9f/8jIiNpndXt699m0YdcfR/fv/X07m81x6djZpdapZAAaQPuiQzNAwxxZnRk4w06Xy8AdBKfHt4p5JszOfXi4g4DmBsf+AAAUBfUHAKAoqD8AAEVB/QEAKArqDwBAUVB/AACKgvoDAFAU1B91icViuVyBOwUA2ED9UY5YLEYIPXv2rE+fPgoF1B+gLqg/ChGJRPPmzZszZw5CyMrKKiYmRksL3vUIqAvqT/Ndv3597ty5xMJDY8eODQkJQQgZGxvjzgUAZlB/mkkgEPz999+5ubkIofT09MmTJyOE9PX1vby8cEcDQF3Avo9GKSwsFAgE9vb2Gzdu1NfXHzRoEEJowYIFuHMBoI6g/jRBWVmZoaHh+fPnQ0JCNm/ejBDauHHj5zzQxFpHQfkpf7RYdJYu7AZRETzr5CYQCCZPnrx3716EUM+ePW/cuOHi4vL5D6fRlaXvxE0ZkATyXlcbmsOqmFQE9Uc+SqXy2LFj06ZNIxbGXbp06apVqxBCZmZmX7qp1h3ZxXmipolJDlKJgkZHFi10cAcBGED9kUZxcfGxY8eqq6vFYnF5efny5cuJsxkdOnRo9DbbdTeoKpM+jylTaVIyCT/x1jvImEan4Q4CMIDZntVdUVFRdXV1ixYtlixZYmdnN2fOHAZDxZMzXzv8jmusbWimbWKlS6PAH0QaDQn4Un6R9El48ZDZ1mY2da9RBzQe1J+aEovFLBbrxIkTp06d2r17d9u2bT/jQY33Ir4i63m1TKosydP8Q4HVoiojE46NA7uLn6Eum9IT/VMc1J/ayc3N3bRpU//+/YcMGZKbm2tjY4M7kaZJTU29evXqkiVLcAcBmEH9qYvo6OhHjx599913T58+ra6u7t69O+5Emm/79u3+/v7t2rXDHQTgQYEjPertxYsXfD4fIXTmzBkPDw+EkIuLC3Rf85g8efKmTZtkMhnuIAAPGP3hIRKJdHR01q5dm5aWtn//fg6HgzsRdcnl8qioKC6X6+YGCwRTC9Rfc8vMzNy1a1dgYGC/fv3y8/MtLCxwJwJILBbPnTv3l19+gZkgKAXqr5lkZmbm5OT4+PiEhYWx2Wxvb2/cicCHKisrS0pKiouLu3btijsLaA5w7K85PHz4cOnSpcQe7oABA6D71BOXy7W1tT106NCVK1dwZwHNAUZ/TUUikezevTsvL2/nzp18Pp/H4+FOBD5XfHy8u7t7RkaGvb097iygCcHoT/Xu37+PECooKLC1td26dStCCLqPXNzd3RFCV69eJaaGBZoK6k9l5HI5QmjkyJHh4eEIIVtb2zFjxjCZMKUYWc2fP5/4u1VZWYk7C2gSsPOrAgUFBfv37x85cmS7du2IqfdwJwKqdOnSJYlEMnLkSNxBgIrB6O+rZGdnI4RCQ0M7d+5MvHkAuk/zDBky5PXr18RzDTQJjP4aqaCgYN68eRMmTAgKCsKdBTSHioqK6upqPp/v5OSEOwtQDai/L3b16tXAwMC0tDQGg9G6dWvccUDzUSqVEyZMWLVqlbOzM+4sQAVg5/fLjB07NjMzEyHUpk0b6D6qodFop06dqqiowB0EqAaM/j7LyZMnTU1NBwwYIBAI4P25ACE0ceLE48eP02gwTTSJwejv08LCwoqKivz8/BBC0H2AsG7dOmJRPUBeMPqrV1hY2OXLl/fu3SuVSrW0YCUwULdHjx4RM5UB0oHRXx2Iy1yjo6PXr1+PEILuAw24cuVKXFwc7hSgMWD09x9CofCnn36aOnUqnNoDny80NHTYsGG4U4AvBvX3H+fPn+fxeL6+vriDAJLJyMig0WitWrXCHQR8Aag/hBBKTk7eunXrsWPHcAcBJLZ7925DQ8NJkybhDgI+F9QfQgj9+OOP8+fPNzU1xR0EkFtVVRWDwdDR0cEdBHwWStdfQkJCTk5OcHAw7iBAc0RERLRp0waWJyUF6p75zc/PP3DgwODBg3EHARqlb9++U6dOLS0txR0EfBoVR38CgSA/P5/H45mYmODOAjSQTCbLz8+HAaD6o9zor7S0dPz48TY2NtB9oIkwmUx9fX0YAKo/atWfRCLJzs6+dOkSHJwGTUpfX/9///tfVlYW7iCgIRSqvx07diiVys6dO+MOAihhz549KSkpuFOAhlBlJYq4uDhzc3MWi4U7CKAKS0tLS0tL3ClAQ6gy+rO0tBw/fjzuFIBaUlJS9u3bhzsFqJfm19+WLVuio6Pt7OxwBwGU065du6tXr+bn5+MOAuqm4Re+3Lp1y8rKqkOHDriDAIoqKSlRKpVwmYF60vD6AwCA+mjszm9kZOSmTZtwpwAA+fr68vl83ClAHTSz/kpLS6Ojo3/44QfcQQBALi4uT58+xZ0C1AF2fgFoWjKZTKlUwpzhakgDR3/nzp2LiIjAnQKA9+h0OiwIp540rf5SU1Pv3LnTt29f3EEAeO/Ro0cLFizAnQLUQdPqz8nJCS40BWqFy+USi2cBdaNRx/7evn1bXV3t6OiIOwgA/1IqlTKZDI79qSGNqr8+ffpcunRJX18fdxAA0MyZM4VCoVKplMvlMplMR0dHqVRKJJIzZ87gjgbe05wpD168eLFt2zboPqAm3N3d9+/f/8GNFhYWmOKAOmjOsT9nZ+cuXbrgTgHAe6NHj7a1tf3gxk6dOmGKA+qgIfUXHx9/+PBh3CkA+BeXy/X39699i4WFxZgxY/AlAh/SkPo7fPiwi4sL7hQA/MeYMWNqVvxQKpUuLi4dO3bEnAnUogn1J5PJ1q5d6+7ujjsIAP+hr68/aNAg4mNLS8uxY8fiTgT+QxPqj8lkmpmZ4U4BQB3Gjh3bokULhFDHjh1h6KduNOHM77Rp07777juY1A98pYoSKY2u8nen6QQOHHnhwoXhQyZUlslUvXFEoyEOTxNexViQ/ro/gUAwYcKEixcv4g4CyCovQ/gkoizrebVlK93KMinuOF/GxJqV91ro4MrpNcyEqaUJO3PNifT1B8DXyH5R/fB6SY8h5vomWiSdmEAikpfmi2+fyJu2thVLj4E7DpmQvv74fL62traenh7uIIB8slKq4m+VDZxqgzuICiiVyuNrX8/d4YA7CJmQfrQ8Z86cnJwc3CkAKSXe5fuOt8KdQjVoNFqf0RaRF4txByET0tefWCx2cnLCnQKQT3mJtKJEqqVN+pdADX1j7ewXVbhTkAnpn/tz587hjgBIiV8ktXbUqGMmPFNtlh6D7IezmhO566+iogIWUQWNo1QgQbnqr0TBqyBLRNITOFiQu/7++uuvS5cu4U4BACAlctefUqmEq50BAI1D7uvFZ86ciTsCAICsyD36S0tLE4vFuFMAAEiJ3PU3c+ZMqD8AQOOQuP6USmWrVq1gdnsAQOOQuP5oNNqRI0dwpwAAkBWJ608ikaSkpOBOAQAgKxLX35s3b9asWYM7BQCArEhcfwwGA9b3AAA0Gonrr2XLlqtWrcKdAgBAViSuP4FA8OrVK9wpAPgqI0f779i5EXcKiiJx/SUnJ+/cuRN3CgAAWZG4/thsdps2bXCnANT1Ni+3ztmlYMopsiDxe35h5UDQzKRS6ZE/9oXfuSEUVru4uKWlvZg4YfqQoBG7f918/8GdJYtW/b5/59u3b7Zt/d3WpsXhP36Pi4uuqhLY2rYYN3aqn+9AYiNyufz4iUNXr10QiYSurl3FIlHN9kUiUcjhvXcibkokYlubFqNGTezbpz++H1fzkbj+KioqiouL7e3tcQcBVLH/4O7Ll89NnzbHxMRs3/6dYrHIf2AQ8aWqKsHhP35fuOB7kUjo1tn9XX5eaurzIUEjDPR5D6IiNmxcZW1t6+zUHiG0+9fNV66G+g8M6uTi9ig+plJQSWxBoVCsXPVdfn7e+HFTeTyjpKTH69avEImEAf5DsP7QmozE9ZeUlHThwgU4/Aeah0KhuHo1dFDA0NGjJhJ7uBs2rnqWnNTFzYO4CH/JolXOzu+nX7OytD565G9i5lF//yHBw/2io+85O7VPS0+9cjV0wvhvpn0zGyE0YEBg0j8JxEMeREY8fZZ4+tQVExNThJCf70ChsPp86Gmov6ZD4vrjcrmtWrXCnQJQRaWgUiKRWFvbEp8SH1RWVhCf6ujo1HQf4dXrtKPHDrx8mULs8JaWliCEIiMjEEIjRoyvuRud/v74+8OHUTKZbNyEoJovyeVyNpvTLD8cRZG4/jp37ty5c2fcKQBVcDlcDpvz7FnSyBHjEUIvXiQjhFrbOxJf1dX9z7IhTxLjl38/r7Nr12VLf2LrsVevWapQKhBCBYX5HA7HQN/g4+2XlZUYG5vs2La/9o0MJolfoeqPxL9cgUBQXl5ubW2NOwigBDqdPnbslEMhe9ZvWGliYnbp8t/Dh421tW1R551PnAixsrLZuGEXk8lECOnq6BK38wwMBQKBRCLR1tb+4CFcrj6fX2ZubslisZr+pwGI3Be+PH78eMeOHbhTAAoZOmSUe9fuZWWlAkHlyhXr585ZXN89yyv4Dq3bEN0nkUiqhdUKhQIh1KaNM0LoTsTNjx/i5uYhl8svX/l35UKhUNhkPwpA5B796enpmZiY4E4BKGTdhhX6+gaenr0QQjREKyjINze3qPOerq5dw8KuXL9xSZ9r8Pf5U5WVFVmZr5VKZZ/e/U6cDNmxc2Nm5mtHh7bPU54WFxcRD+nnF3Dlauj+A7vf5ee1cXR69SotKvru0SPndHR0mvenpBAS15+Hh4eHhwfuFIBC3Dq7Hz124E5EGPEpg8FYtmR1//6DPr7nN1O+LS0p/m3PVi5XP3DQsFEjJuzYtTEx6bFbZ/fNm37b/dvmy1fOsdkcn16+BgY84iFaWlpbN+89FPJbRETY1auhNjZ2QYNHMOHYX1OikfcKdYlEIhaLuVwu7iCAlLJSqpMe8H3HWn3+Q+RyOYPBID6uqKz4/of5TCbz110hTZbxix1b82ruTgfcKUiDxH9bYmJirly5sn37dtxBAFVs37Hh9es0T89ePJ5hzpusjIz0QYOCcYcCjUfi+mMymXCODDQnDw+vwsL886F/SqVSS0vrSRP/N7LWFXyAdEhcf97e3t7e3rhTAArp7ePX28cPdwqgMiS+8EWhUMhkMtwpAABkReL6e/DgwfLly3GnAACQFYnrDwAAvgaJj/317t27d+/euFMAAMgKRn8AAIoicf3du3dv8eJ633QJAAANI3H9AQDA14BjfwAAiiLx6A+u+wMAfA0S1x9c9wcA+Bokrj8mk6mrq4s7BSArGl3JMdDCnULFLO11yTuHU/Mj8bE/eM8v+BpG5tpvXhZ1CzDFHURlygrE4mo5sbwc+BwkHv2JRKLS0lLcKQBZcQ21jC21RdVy3EFUprxI0rK93mfcEbxH4vp7+PDhhg0bcKcAJOboQb994i3uFKpRXSGNuVJo41KNOwiZkLj+9PX1bW1tcacApMTn80eNGmViw/AbY3ZhT1ZBjpC8w8DKMmlOquDCbznT1rZKSUlZvXo17kSkQeLJ7gFotEuXLnXo0KF169YIobICyePwsqyUKq6RVkWxFHe0L2Nup8MvlrTuxPYOen8Q89q1a87OzhYWFnp6sCP8CSSuv+rqaoFAYGZmhjsIII03b95s2rTp999/r/OroioFjXS7Q0olS4/x0W3KoqKiXbt2bdy4EVMsciBx/d27dw/W+gBfZMWKFfPmzbO0tMQdpDmEhYXl5OT873//wx1EfZHuj92/dHR0eDwe7hSABNLS0o4fP44Q2rhxI0W6DyE0YMCA6dOnI4R27NiBO4uaIvHoD4DPNHPmzK1bt+rr6+MOgkdcXNzVq1fXrVuHO4jaIXH9wTq/oGGpqalpaWlBQUG4g6iLkJAQYjwICCTe+Y2JiVmzZg3uFEBNvX79et26dX2KsPsoAAAgAElEQVT79sUdRI106dKla9euCoUCdxB1QeL6g2N/oE65ubkIIQaDcerUKQ6HgzuOGuncuXN8fLxCocjOzsadRS2QeOcXgI9FRUUdOHDgxIkTuIOotbKysqFDh164cMHIyAh3FpxIPPqrrq4uLCzEnQKoC2Lyx8rKSui+TzI0NLx27Vp6ejrFd4RJXH+PHj3avHkz7hRALURFRS1duhQh5O/vjzsLOXA4nG7dutFotDFjxlRWVuKOgweJ64/D4VhZWeFOAdTCzZs3d+7ciTsF+dBotHXr1u3btw93EDzg2B8gsZKSkqSkJF9fX9xBNMGZM2dGjx6NO0WzIvHoTyqVVlVV4U4BsCkvLx87dmy3bt1wB9EQ9vb2EydOxJ2iWZF49Afv+aWygoICsVhsZ2eHO4hGeffunaWlZVZWVsuWLXFnaQ4kHv0xGAwtLU1bqwF8jpkzZzKZTOg+lSPeEP3y5UuKHA0k8egPUJBcLr99+7apqWmXLl1wZ9FkISEhY8aM0fiLxklcfzKZTCqVwmJv1BEfH+/o6MjhcJhMEi/RRRYymSwiIqJ///64gzQhEu/8RkVFrVq1CncK0EwyMzMPHz7M4/Gg+5oHk8n09vbu2rWrXE7WZQA+icT1x2azYapnipDL5cXFxfv378cdhFr09PQeP35cXFysqddFk3jnF1DE3r17iXMduINQ16NHj1gsVqdOnXAHUTESj/5gnV8qSEhI0NXVhe7Dy8PDY/fu3SKRCHcQFSPx6A+u+6OCly9ftm3bFncKgBBCRUVFpqamuFOoEolHf3Q6nU4ncX7QsPDw8GvXrkH3qQ9TU9MtW7bk5eXhDqIyJB79AQ2WkJCQlpY2duxY3EHAh1avXv3DDz9oxgVnJK4/hUKhUCjgqBAAoHFIvPP44MGD5cuX404BVG/Hjh1isRh3ClCv5OTky5cv406hAiSuPz09PRMTE9wpgIqtWbPG0dGRxWLhDgLq1aFDh6ioqDt37uAO8rVIvPMLNI9UKpVIJGw2G3cQ8Gl8Pp/sa42RePQnFov5fD7uFECVkpKS4GAuWQiFwlevXuFO8VVIXH+xsbGwcL0muXz58vXr12G3lywsLS2//fZbUr/1gMT1B/P9aZjy8vLFixfjTgG+wM6dO5OTk3GnaDw49gcAoCgSj/4kEommTkRBQRcvXkxPT8edAnyxmzdvPnv2DHeKRiJx/cXExKxZswZ3CqAa69evd3R0xJ0CfDEOhxMSEoI7RSOR+Cybjo6OoaEh7hRABcrLy0NDQ3GnAI3h7e3N4/GUSiWNRsOd5YvBsT8AAEWReOdXLpfDW6M0w+7du1NTU3GnAI107ty5iIgI3Ckag8T1FxkZuWLFCtwpgArcunWL7O8foLi4uDjcERqDxMf+DAwMWrRogTsF+FpKpXLXrl0WFha4g4BGCggIIOnFz3DsDwBAUSTe+ZXJZEKhEHcK8LWKi4vhIAap5eXlkfQSNBLXH6zzqxlEItHz589xpwCNJxaLSfrWN/Lt/C5cuDAyMlKpVNLpdIVCQfxrbm5+48YN3NHAF/jll1/Onj1b+0mk0+lyuTwxMRF3NPBZNm3adObMGSaTSVz0V/M8PnnyBHe0z0W+0d+kSZOMjY2JRY6If2k0mru7O+5c4MtMmjTJxsam5kkk/u3atSvuXOBzjRs3zs7OjngBEs+gUqkk1yuRfPXn5ubWrl272oNWa2vrSZMmYQ0FvpiVlVWvXr1q32JgYDB58mR8icCXadGiRY8ePWq/Enk8HrmeQfLVH0JowoQJtae579atm4ODA9ZEoDHGjRvXsmVL4mOlUmlvb+/t7Y07FPgC48aNs7W1rfnUwcHBy8sLa6IvQ8r669q1q5OTE/GxjY0NLIdIUlZWVj179iR2nXg83sSJE3EnAl/G1tbW09OT+NjAwIB0zyAp6w8hNHnyZBMTE+JYg729Pe44oJFGjBhBDADt7e0/2BcGpFBzBLB169akG7yT9V0fbm5ubdu21dLSGjVqFO4soPGsra29vLwKCwvh6C1J2dra9ujRo6SkhFxH/QifuPCl6K04MYJfkCMSCuTNmOqzKJQKhULBZKhdg5vbsRQKZN+R3akXCd7HGnezJCdVyNSiFeXimT9CiZQymVwL3wpHpjYsOp3m4Mpu72mAK8Pni7lSnJsuZGjRSvIkuLO8h/0Z/JiZHQspkX1HtkvPhl6DDdVfVkpVzJUSFx8jnqm2LkeNfjZ1p1QWvxOX5IkKsoXBs61xp6mXTKo4+nNWl37G+kbaPAsWUuAOhIlCrix5JyrIFkmEsn7jzXHHqZdYKD+yOstriCnXUNvQTFtB1efrcygVypJ34qJcEb9QHDjdsr671Vt/qfEVKY8q+01Q31ev+kt7Up6VLBg+T01/h/uWvQqe25JtAH/Y3nsWVcovEAd8U++rBSOpRHF4VeaY5a0YTLIer8fixSN+3quqod/W/Rqs+1cpqpanxEH3fa02bgYWrXSfRZfjDlKHBxeKeg23gO6rraO3kZ6BVtqTCtxB6nD/fJHveCvovi/l7MEzttZJiav7NVj3b/NdhojBJN/U1WrI0IyVlVKFO0UdXiUKTKx1cKdQOwbG2jmp6jiPRlpCpaktPF+NwTNhZadU1/mluuuvokRq3kKviVNRgrElS6l+x2iEArmxJUuPC0O/Dxnb6Mgkavcu+LJCSQtnDoMBI5LGMLFmKeo5cVv3C0AsUsjU5bQSudHo2M6oNkCpRMV5apdKHdCUqDRf7f7rKxWIX6R2qciDVt//djiUAACgKKg/AABFQf0BACgK6g8AQFFQfwAAioL6AwBQFNQfAICioP4AABQF9QcAoCioPwAARUH9AQAoCuoPAEBRlKi/lBfJYvHXvsNfJRsBqpWf/+5dfh7uFBpo8JDe+/bvwp0CIYTSX73s49s1NjayKTau+fV3M+zKnLlTRKKvmsRNJRsBqvU2L3fchKCXL1NwBwFkpfn1p5IhG4z7PlBezq+obPJZkRteh0sukzV8B0AWuJ5HlU14OXhI74ULfoiKuvswLorN5gwOHD550v+IL5WUFO/bvzPuUbRMJuvYwXXWzIX29g4Nb00kEp04GXL37q2i4kJzc8v+/QaNHzeVwWDUt6lVqxfb2rRgMplXr12QSaXdu3svmP89h8O5GXZl1+5fEEJDh/khhJYv+2nggMEIocSkx4dC9rx+nWZoaNTZ1X36tDnGxiYRd2+tW79i7c9be3r3QQgRn27asItfXlbnRqgmLOzqqdN/FBbmt2rZmkanW5hbrv5xE0LoXX7e77/vSHgSp63NauPo9M03s53atmvgSSG2dunyubN/nywuLrSwsPLtO3D0qIksFqu8nD90mN+smQvSX72Mjr7n6Oi0bcvvx08ciogIKywqMDY26d9v0JTJMxkMxrv8vMlTRyCEfl77/c8IDRgQ+P2yNQ2EoZSoqHs//rTkzOlrZmbmCKHk5H/uP7gzZ/Yi4qs7d22KexT9159X63shEHfLyEift2Baenqqqan5qJETBgcOI27/8/TRi5fOVlZWODi0nTJ5Zhc3jwa2c+Pm5YsXz2ZkvtLV1fNw95w7ZwmPZ4gQunc//Oe136/7eduZv0+kpj4fO2byN1O/rfNVT3zTzKzXf509/vJlio2N3YJ5yzt2dFXJL0qVo79fNv/k4NB2185D/fwCjh478PBhFFFki5bMSnjyaMb/5i9auKK4pGjRklmVgsoGtiOXy1esXHj275M9e/ZdtmS1Ty/fN7nZDAaj4U2d/ftkfn7exg275s5Zcu9++MlThxFC3Tx6jBo5ASG0acOuX3eFdPPogRBKePJo2fK5LVvYL1n846gRE54+fbJoySyRSNS3T//u3b33/r5dJBKVlBTv2v1L4KDg7t2969wI1URF3/tly5pOLm6rVmzQ0tZ+8SJ5xPBxxN+2efO/qagsnztnycwZ86VS6YKF0zMzXxOPqvNJQQgdPXbw4KFf+/bpv3TJ6t4+fmfOHt++c0PN9zp58rCFueX2bfvnzF7MYDASEuI8vXp9O+s7t84eJ08dOR96GiFkbGSycsV6hNDUKbN+3RUyYdw3nwxDHe3buyCEomPuE5/euHn51u1rEokEIaRQKCKj7vr08mvghUA86tXrtB5ePrNmLuRy9Xfs3Pj3uVPEQw6F7HFxcVu0cIWFuaWwurrh7aSkPLOzazlzxvzBgcOiY+5v3vpz7Zy7f9scGBC8ZfOewYHD63vVE/c8eepwZ1f3hQu+l0gkK39cJBAIVPKLUuV05wH+Q4i2dmjd5tr1i48ex3bv7n07/HpOTtb2bfvcOrsjhDp27DxuQlBo6F81Y8OP3X9wJzHp8dIlPwb4D6l9e8ObsrGxW/HDOhqN5uzU/kFURPzj2FkzFxgaGllZ2SCEnJ07GBi8X/Hztz1bBwcOmz9vGfFp167dJ08dEf84tqd3n4Xzv586beSJkyEZma/0ufqzv12EEKpzI1Rz6dLfLVvaL160EiHk5NR+5Gj/h3FR7dp1PHEyxJBntH3rPiaTiRDq5xcwYdLQq9cvzJuzpL4npbi46NSfR1at3ODTy5fYuLGx6c5dm+bOWUJ82q5dx+nT5tR869/3HqPR3s/znvcu90FkxKiRE7S1tds4OiGE7Oxa1owFGg5DHYaGRm0cnWJi7gcPHSUUCu/dv11dXf0gMsLPd+A/T5+UlZX6+Pg1/EJACPXvN2jM6EkIocGBw+YtmHb02IHAQcPy8/MQQsFDRrVv79KvXwDxwAa2s+i7FTXPHZPJPHnqiFgsZrFYxC3BQ0cPGBBIfBxx91adr3rCgnnLiXu2sGs1e+6UhCdxNf95voYq609HR5f4gMFgmJqalRQXIYT++SeBw+YQhYUQsrCwtLNr+TKtocPVj+JjWCzWgP6BH9ze8KZ0WDo1v2hzc8vk5H/q3Hh+/rvs7My3b99cvXah9u2FhQUIIXNzi2nfzNmzdxudTv91V4iurm6jfhMaqLCowMbGjvjYxMRUR0ensrICIRQXF11YVBAQ2LPmnlKptKiwgPi4ziclISFOJpNt2Lhqw8ZVxJeIQz/FRYXEHpObm0ftb11WVnr8xKH4xw+J78jlcOsL2XAYSvHx8fvj6H6BQBAVfRch5Oc78Nq1C36+A+/fDzc3t2jn3KHhF0JtDAZjyOARv2xZ8/JlSvdu3lyu/sZNP86bu7R7d+9PvqCkUmnohb9uh18vLMxnsXQUCgWfX2ZubkHcp/YTXd+rnqCv/34F+pYtWyOEiopU85w21WI3TAZTrpAjhARVAgOeYe0v6esbEM1Yn7LSEhNj05pxb43P35QWU0tRz+omZWUlCKHJk2b06tm39u1GRu8PeQzoH3jg4G4Hh7bEHgQgWFnZvHyZIpFItLW1MzJeiUQiB4e2CKHSshJPz54zps+rfWc2m/PxFmqelJLSYoTQxg27zEz/s6a4lZVNVZWg9t9RhFBpacmMWeN1dfW+mfqtlZXNkSO/v8nNri/k54fReD4+fodC9jyMi7p+41I/v4DAQcP+N3NcTk7Wg8iIfn4Bn/NCqM3YxBQhVFUlMDY22fPrkb37dvywcmGHDp1Wr9rUwHaUSuWKlQtfpqVMnjSjXTuXyMiIv84cV9Ra+ktP99/11Op71X+ATqcTx8e+4nfzryZf68vUxCwl5VntW0pLS8zNLBp4CIfDLS0rUcmmatScWuJwuAghsVhkZ9eyznsePPQrk8l88SL52vWLgwKG1rkRCho7evKiJbMWLZnVxc3j9u3rTm3bEX+ouVz98nJ+fb/MOnG5+sQHn/Ooy1fOl5WV7v3tKDFkMDOzaKD+GhFGU1lb2bRxdDp//s/UlykL5i1v3drR2bnD5q0/1+z5fvKFUBufX4YQMjIyJp61zZt+fZIYv/qnJZu3rFkwf3l920lKSkh48mjlivV+vgMRQm9zcxr4FvW96ptUk1/40r69S2VlxYsXycSnr1+nv337puETN507uwuFwjsRYTW3yGSyxm0KIaSro4sQKv7/QaKNjZ25ucWNm5eFQmHNxqVSKfHxk8T4K1dD58xePCRoxJ6923JysurcCAV16NBp+LCxCoUiLy939OhJu3YeIo6vubl5JCf/8zLtRc09a36x9enc2Z1Go124eOZzHlJRwefxDGt2l8or+DV/hFgsHYRQ7eF/I8JoMB8fv9SXKe3bu7Ru7YgQGjJ4RErKM2LP95MvhA/cvx/O5eq3bt0GIUScQnHr7N69e8+09NQGtlNewUcIEYdoaz5VKOpe+LW+V32TavLRn5+v/6k//1izdvnECdPpdPqJEyE8nuGQoJENPKSfX8DFS2d/2fxTaupzh9ZtMjJfJTyJO7j/VCM2hRBq36ETg8HY8/s2/wFBYok4aPDwObMXr/5p6Zx5U4IGj1DI5WG3rvbrFzBi+DihULht27qOHV0D/IeI+w5MePJo3foVv+89pqWl9fFGVP17Und/nzuVmBg/atREGo3GZDJzc3OIF9XkSTMePoxaumzOqJETDA2NHj2KkSvk69dub2BTNta2w4LHnA89vWLVd949epeUFF+8dHbTxt01r5PaXF27Xrh49sgf+9q37xQZGREXF61QKMrL+QYGPDMzcytL67PnTuro6lZUlA8LHtOIMBqM2P8dMngE8Wnv3v327ttBnPNFCNFotPpeCMQdwm5dNTIy1tHRjXsUHRsbOX/eMm1t7Repz39eu3zokFG6unqPHsU4tW3XwHbaOXfU1tY+FLJn0KDgjIz0P0//gRDKzHhlbWXzcdr6XvVN+itq8tEfk8ncunlv2zbt9u3f+duerXZ2LXfvPGRoaNTAQ1gs1vZt+wf0D7wdfn3Xr788io/p1dNXJpM1YlPEXsDiRSvfvMnes3fbvXu3EUI9vfts2rBLi6m19/ftx0+GmJtburi4IYQOhfxWVFy4+LuVNBpNR0dnxQ/rMrNeHzj4a50boZq2bdqVlpVs2Lhq/YaVa35ePn3G2B07NxK/mT2/Hmnf3uXUn0f2/r6dX17m5+v/ya3Nmb3o21kLMzNe7dy16dr1Cz29+5iamNV5z149+06aOP3ipb83bFgplUn37jlqZ9eSGDnSaLRVqzbq6bH37N12M+xKWVlp48JoKmsrmy5uHsSuLvGy8h8YVPNpAy8EhJC2Nmvc2Cm3bl/b+/v2t2/fLF3yY/DQUQghbS3tFnat/vzzj5CQPS4unZcs/rGB7Ziamq1auSH9Veqan5clJMTt2H6ge3fv0At/1Zm2vld9k/6KaHUez3oUVioRoU69P9Es4JOEAvmV/TnT1rXCHeQ/qivlp7fkjFryZankcjlxZFoikRw49OvFi2fDbsQQu8Aag18oiTyfP+57O9xB/qM0X3LjaH7Qt+qViiwEfNmtY7mTV9dxiBPb/935C6dnZr76+HYvL58flv9c1yMATrduXQs5srdP7/6WltZlZSWRkREtW9prWPcBqsH233f1qk1SWR3HWXV14FI7ddSipX3HDq7hd25UVJQbG5v08PKZMH4a7lAAfBVs9WdiYorrW4NGaNvG+cdVG3GnAECVNH/GFwAAqBPUHwCAoqD+AAAUBfUHAKAoqD8AAEVB/QEAKArqDwBAUVB/AACKgvoDAFBU3e/6YGrRFRSe2lOFaHTEM9HCneJDSrmSZ6qNO4VaotM4hmr3RmaFEnHVLxVZ0OiIa1T3a7Du0R/bgFH6Dla2VYHyIgmi4Q7xETaPWfRWJJXUPfEklZUXiRlMtXvCDE21ctOrcacgq/IiCb2evdy6bza20FYqYPSnAhWlEhtHdZzEoVV7dnmxBHcKtVNVLrVurYM7xYcYTJptG73KsrqnYgYNE/Cl1vW8BuuuPxNrFofH/OdBaRMH03AyqSLuWnE3f2PcQerg3t8oKpSKS6A1oKpcmhJb7trb8DPu29zc+hpGns/HnYJ8xEJ5QniJe7+6py6te7pTQsTZIjqD1snHiKkFZ0i+WNFb4b2/8scstdPjfmLxKlwKckThfxb6jrNkG6jd0cnm9y6zKuZS0dhltixdNX2+sl9UP7xR0meMpS4bjgN+loIcYeT5grFLbXXYdT+nDdUfQij+VmlyTDlTi67LVbvfuFKpVCqV9Pp26/HRN2K+/kdg78L2GW6qo6emryVCQbYoPrz03WtRi3acilJM+1ZKpUKhoH9qhcOmw9ZnZjyrbNOF4zvanM5QuwN/tb1Jq068W1b4RmLbRq+S3+QrAX0u3M/gx7g85uunlQ6u3N4jTbVZ9VbEJ+oPIaRQKMuLpdUVqllYU4WSkpJiY2O//fZb3EE+xGDQTWy0SDRkFlXJSwskSkwnQoqKinbv3r1+/Xo83x4hhhbNzIal5sVXW3WlrKxQitTm4Hx+fv6+fft+/lmNJmlnMukmNtqfPIv16TEdnU4zNNM2rHshGpzSc8VC9NbaQR1PLJCLDpthZY/t16jUoZeJXsPz+Pn0uEw9ddobkzJpJH0GSTNCAQAA1SJx/dHpdB0dtbtGATQCh8PBHQE0Ho1G43K5uFM0Bonrj8lk6uqSb7wNPiYQCHBHAI1Ho9EMDAxwp2gMEteftrb2J8/bAFKwt7fHHQE0nlQqJel+GInrj8PhCIVC3CmACmRkZOCOABqvoqKCpPthJK4/S0vLd+/e4U4BVMDW1hZ3BNB4BQUFsPPb3AwMDKqrq/Py8nAHAV/rzZs3uCOAxktOTrazs8OdojFIXH8IIVdX15iYGNwpAKC0yMjIbt264U7RGOSuv0GDBsXFxeFOAb4WSS+bAAih1NTUVq1a2djY4A7SGOSuPxcXFx0dnbS0NNxBwFeprKzEHQE00p07d/z9/XGnaCRy1x9CKDAw8MiRI7hTgK/SsmVL3BFAY7x9+/bx48cDBgzAHaSRSF9/3bp1o9PpYWFhuIOAxsvKysIdATTG2rVr58yZgztF45G+/hBCGzduPH36tEymNvP/AEABV65ccXV17dq1K+4gjacJ9YcQWrly5dKlS3GnAI1Bo9EcHR1xpwBf5uXLl3fv3lXD6ea+iIbUn6Oj46hRo2bPno07CPhiSqUyPT0ddwrwBUpKSmbPnr1jxw7cQb6WhtQfQsjT03PNmjXffPMN7iAAaLKioqJly5bduXMHdxAV0Jz6QwiZmZlNnz79hx9+wB0EfBmSvmeAgpKSkiZOnHj48GHcQVRDjeaMVQkvLy8jI6Nu3bqdOnXKwcEBdxzwWXJycnBHAJ929uzZsLCwmzdv4g6iMho1+iM4OTlFR0cfOHDgjz/+wJ0FAA2xfPny7OxsjRn3ETSw/oiZULdu3VpVVTV58mSYFUb9mZmp31Iy4P89fvy4R48e/fr107yLKzRt57e2uXPnJicnL1682NvbG04Kq7PCwkLcEUAdJBLJmjVrdHR07ty5Q9IJTRummaO/Gh06dPjzzz9ZLNbkyZNv3bqFOw4ApHHy5Mm+ffv6+PisXr1aI7tP8+uPMG3atO3bt9+9e3fChAmPHz/GHQd8iM1m444A/hUWFjZgwICioqKoqCjyvp/3c3x6mXNN8uLFi7179wqFwilTpvTs2RN3HIAQQrm5uXPnzr148SLuIABdu3btzz//bNGixaJFi0xMTHDHaXLUqj9CUlLS0aNHc3Nzp0yZEhgYiDsO1eXm5n7//fcnT57EHYTSzpw5c/ToUXd39ylTplBn5SlK7Px+wNXVddeuXVu3bo2Pj+/fv/+pU6dwJ6I6WOgSF7lcfvjwYW9v7+zs7GPHjq1du5Y63UfR+iO0atXq559/Pn36dEFBQbdu3Y4fP56bm4s7FADNhLiIz9PTUywW3759e9myZRS8/IiKO78fk8lkoaGhp06dsrS0DA4O1uzDveomNzd3x44dGvD+ebIICwsLDQ0tKiqaMGHCsGHDcMfBCervP+Lj4y9cuBAZGRkcHBwcHNyqVSvciTQfnPpoHrm5uefPnw8NDe3Ro8fw4cO7dOmCOxF+mnzZcyO4u7u7u7tXV1dfuHBh6dKlBgYGwcHBcHoEkNq9e/fOnj379u3b4cOHX7t2jcPh4E6kLmD015CkpKQLFy5ERET07t3b39/fy8sLdyINlJubu2XLll9//RV3EE2TlJR0/fr169ev+/v7+/n5kXQtyiYF9fdZrl+/fuPGjefPnw8cONDf379jx464E2kO2PlVrczMTKL1LCwsAgICAgICdHV1cYdSU7Dz+1mI/0bl5eU3b97cvn17WVkZ0YOwRJlKwHx/X6+srIxoPbFYHBAQcPjwYQsLC9yh1B2M/hojNzf35s2bN27caN++vb29fd++feEF3Ggw+vsaFRUV4eHhsbGxiYmJxB9pJycn3KFIA+rvq7x8+fLWrVsREREsFsvX19fX15dSV42qRG5u7vz580NDQ3EHIZPy8vLw8PDw8PDU1FQ/P78BAwaQesU1XKD+VCM9Pf3OnTt37txRKBRED7Zt2xZ3KHKA0d/nq2m9ly9f+vn5+fn5eXh44A5FYlB/KpaVlUX0YFVV1bBhw1xdXTt16oQ7lFqD+vukgoKC+/fvJyQkxMfHQ+upENRfU8nNzY2Li7t27Vp2drbP/8MdSh1B/dUnPT39/v379+7dKy0t9fHx8fPzg2uVVQvqr8nx+fz79+/fv3//wYMHvXr1InqQx+PhzqUucnNzN23atHfvXtxB1EVCQsK9e/fu37+vp6fn4+PTu3dvZ2dn3KE0E9Rfs7r//+zs7AYNGuTq6grL0cHoj5hWPjIyMiUl5dy5c23btu3du7ePj4+1tTXuXBoO6g+Pp0+fJiYmXr9+XSAQeHt79+rVq0ePHrhDNatFixbdvXuXTv9wzqGEhARMiTDIzc2Niop68OBBYmJiz549+/Xr5+npCW9KazZQf5jl5+cTL4CYmJgePXr07NnT29ubChesvnjxYunSpfn5+TW3KJXK1q1bnz17Fmuu5pCYmBgZGfngwQOpVEr88YN3pGEB9adGosAK6cgAAAoDSURBVKKiIiMjo6KiLCwsOnXq1KNHD80+1L1y5cqwsLCaT7W1tZcvXz5kyBCsoZoKn8+PiYmJiop6+fKloaFhz549e/XqBVMK4QX1p45ev34dFRUVExPz9OlTLy8vLy+vHj16aN6QMDU1dcmSJTUDQHt7e80b+iUnJ0dHR8fExOTm5np5eXl7e3t5eXG5XNy5AIL6U3cSiSQmJiYmJiY6OlpXV9fLy6tXr16adH3/ypUrb968SaPRWCzW4sWLNWP2zfLy8oSEhIiIiJiYGFtb2x49enh5eXXo0AF3LvAhqD/SyMzMjImJyc7ODg0N9fT09PT09PLyIvucCykpKUuXLi0oKHBwcPjrr79wx/kq//zzT0xMTGxsbG5ublBQUNu2bb28vAwMDHDnAvWC+iMfpVIZGxsbGxsbExMjEok8/5+enh7uaI3x448/hoeHL1u2LDg4GHeWL1ZUVJSQkHD37t3Y2FgHBwcvLy9PT8/27dvjzgU+C9QfueXn58f+P0dHx+7du3t6en5yOsIZM2YcPHiwEd+u5J34XYawtFBWVS5DiCbgyxob/F8Sifhdfn4LuxZfvymEkBaLpsdlsA2YJpZadk5sXQ7jS7cQHx+/evXqGzduNHCfR48eEX9+ysvLAwMDnZycPD09YbF20oH60xz//PPPw4cPY2NjMzMziR7s3r17nSdMunTp4u7uvn///s/cclW5LPFeeVpiJVLSuOYcGo3G1GZo6TARTdU/w1dTyBRSsVwmkSOloiy3kmuk1d5Tv1PPz90DvXHjxs6dO4uLi588efLBl968eUPs28bGxrq5uREHH+CqdVKD+tNAAoGA6MGHDx/q6uoSPejp6UlcYxwUFJSXl6dUKp2dnY8fP/7xhce1SUSKqEslr/4RGLfkcY11tfW0mvHnUIFqvqiaLy7KKPMabNKp1ydK8OzZsyEhIaWlpUqlkrj6WiaTEaeeYmNjaTQasW/r6enJZMI8wZoA6k/DZWZmEj0YGxvr7u7u6el58OBBoVBIfNXW1vbAgQP1LfCamlD18FoJ14xj3ILcx+8VMmXhqxImQ+E/xYytX/fu8KFDh86cOcPn84lP2Wy2s7NzYmIiceGRp6enjY1N86YGTQ7qj0Li4uJiY2NPnDhBo/2712plZbVly5aPpwh+eKP01VOhjYvmXGwoFcleP3w7aLqlreOHa1/s2LHjypUrlZWVtW/ct2+fu7t782YEzQrqj3K6dOlSu/4QQiYmJqtXr669jt2Tu+Xpz8TmjsY4AjatzPi3QTMsjC20a25ZsmRJXFxczYiYULP/CzRYQ8d9gOYZOHAg0X1KpVKhUHA4HEtLSxaLVXuu+egrJenPRBrZfQihVu7WVw4VvMv6t+zkcrmFhYWZmZmBgQGN9n5AQKPRYH1njQejP2rx8vLi8XhsNtvMzKx9+/ZOTk4tW7asvT5JepLg0e0K6w7mWGM2uRcRWdPXt9Ji/fvnv7KyMjMzMyMjIyUlJTs7u6ioSCQSXb9+HWtM0LSg/sC/BHzptSOF5s6ac7yvPiKBRFLGD5phiTsIwAl2fsG/oi6XsniUmGxOh6NdXYXSEio/475AY0H9gfdK8yV5GSKeJSXqDyFk3NIo8lIx7hQAJ6g/8N6TiHKTVoa4U9Rt7ZbAc5d+Ue02tXSYXDNOajwMAKkL6g+8l55YwTH+8II4zcbisNISBbhTAGyg/gBCCOWmV7MNWXQGtf4/6JvqvXlZhTsFwAbeuggQQuhdpohr2lQTlrzKSLh++/e8/DQux8ihVVf/ft/qc00QQqs2+A4fvDz5xb2Ul9G6Opzu7sH9+0wnHiKXy8PvHX74+KJEImxt30UqFTVFMBqdZtma+yat2rYNKecKA1+JWn/tQX0KcyV0ZpP8Z0h/HX/o+Hxzs1ajhq7s5TUuIytx/x9zJJL3dfZX6M9WFm1mT9vv1sn/VsShlJfRxO0Xrm69fe+wUxuv4MAl2lo6QlFTHaGTSJSCMhVM2wXICEZ/ACGEBHwZx6JJ/jNcvLa9e9fg4MAlxKdtHLpt/XX0y1cPO7brjRDycAvy9ZmCELKyaPMo4VLaq4ft2vbIzUt9+PiCr89Uf79ZCKGunQe9zvxw+ilVoTMZVRVQfxQF9QcQQkihQEzWF88M+kmlZe8KijKLS988fPyfVcz55QXEB9ra70+2MBgMA32z8ooihNCzlHsIoV5eY2vuT6M11W4Kk8UUVsubaONAzUH9AYQQkokVSrnq3/9TKShBCPXrM92lXZ/at3O5Jh/fmU5nKhRyhBCfn6+jw2HrNccsWwqZkgbve6IqqD+AEEJ6+gyZRPWDIF0dLkJIKhWbmX7BkkxstqFIJJDKJFpM7c+4+1eRSWRsHsnmcAWqAqc+AEIIcQyYUrHqD4GZmtjxDCzin1wRS97PsCKXy2QyacOPsrF2QgglPg1r+G4qoZDK2fowCKAoeOIBQgiZt2ClP1d9/dFotCEB3x07vfy3A9M8PYYpFPLHide7uA6sfVzvY53a+4XfO3L+0i/5BRnWlm2y3jyrqCxSebb3lApDcxj9URSM/gBCCNk56VUWNskFwB3b9f5mwg4GQ+vy9Z3h944YGlrYt+zc8EMYDMb0ibvaOHSLjT9/New3Oo3O1uM1RTaJUCaslJpa6zTFxoH6gwmvwHt//Jxl1cGCRbbFjL5GSU6FkaGszyhT3EEAHrDzC95r190gN0vIsqu3/p4+v3v24vqPb9disqQycZ0Pmfe/EHOzVqpKeP327zGPzn98u64Ot77roufPONzAWReZSNy2K7lXcQJfA0Z/4F97vnvVvl/LD1YCqSGWCKuqyj6+XSaTMpl1l6aBvhmDobI/sVXV5WJxHXvoSiWqJ3JDASqLqyX8iuHzrFUVD5AO1B/4V/ytsoxUmbmjEe4gzSEjLnfIDAtjKxbuIAAbOPUB/uXe35CBJFKR5r8JrLxA4NCJDd1HcVB/4D+CZli+is3FnaJpVfNF1cUVvYLreOcJoBSoP/Af2jr04NnWWQl5uIM0FYlQmpdcOHaJLe4gAD849gfqUFYoDd2T16qbNZ1ezzkFchKUCN8+L5yxoRVNs34u0DhQf6BuZQWS01tybF0tuCYaMgM+/22lRFA1aiGc6gXvQf2Bhlw7kl+cJzVtbaTHI/FbI8ryBIWvSjv15HUPUNO1nAAWUH/gE/JeC++dL1YgOoujo2+mx2I3+SwsqlJVJqoorKIp5AbG9N7DTXQ5qp/QEJAa1B/4LHmZwvTEqsxnVVp6WhKhnMliaOtpK+QK3Lk+pJQrZRKZTCzX1qUzGMjRle3YiWNgSqF38oHPB/UHvkx5qVRYIa+qkImFColI7eqPxaLr6jPY+kyuIUOHDe/pBA2B+gMAUBRc9wcAoCioPwAARUH9AQAoCuoPAEBRUH8AAIqC+gMAUNT/Adj8laxKvyKjAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/christinemahler/Desktop/AIE5/04_Production_RAG/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1363: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I don't know the answer to that question.\""
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Any, Dict, Literal\n",
        "from langgraph.graph import END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "system = \"You are a helpful assistant that grades the relevance of a document to a user question.\"\n",
        "\n",
        "class Grade(BaseModel):\n",
        "    bool_score: str = Field(\n",
        "        description=\"Check whether the documents retrieved are relevant to the question asked.\"\n",
        "        \"If they are relevant then answer 'yes', else 'no'.\"\n",
        "    )\n",
        "\n",
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  if len(retrieved_docs) == 0:\n",
        "    return {\"context\" : []}\n",
        "  else:\n",
        "    return ({\"context\" : retrieved_docs})\n",
        "  \n",
        "def grade(state: State) -> Dict[str, Any]:\n",
        "    filter_docs = []\n",
        "    websearch = False\n",
        "    \n",
        "    grade_template = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"user question: {question}, retrieved document: {document}\"),\n",
        "    ])\n",
        "    grade = openai_chat_model.with_structured_output(Grade)\n",
        "    template = grade_template | grade\n",
        "    \n",
        "    for doc in state[\"context\"]:\n",
        "        result = template.invoke({\"question\": question, \"document\": doc.page_content})\n",
        "        if result.bool_score == \"yes\":\n",
        "            filter_docs.append(doc)\n",
        "\n",
        "    if len(filter_docs) == 0:\n",
        "        websearch = True\n",
        "\n",
        "    return {\"question\": question, \"documents\": filter_docs, \"websearch\": websearch}\n",
        "  \n",
        "def generate(state: State) -> State:\n",
        "  generation_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generation_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}\n",
        "\n",
        "def no_context(state: State) -> State:\n",
        "  return {\"response\" : \"I don't know the answer to that question.\"}\n",
        "\n",
        "def evaluate_context(state: State) -> Literal['no_context', 'grade']:\n",
        "    context = state['context']\n",
        "\n",
        "    if len(context) == 0:\n",
        "        return 'no_context'\n",
        "    return 'grade'\n",
        "\n",
        "def evaluate_grade(state: State) -> Literal['generate', 'websearch']:\n",
        "    websearch = state['websearch']\n",
        "\n",
        "    if websearch:\n",
        "        return 'websearch'\n",
        "    return 'generate'\n",
        "\n",
        "def websearch(state: State) -> State:\n",
        "    return {\"response\" : \"I don't know the answer to that question.\"}\n",
        "\n",
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder = graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder = graph_builder.add_node(\"grade\", grade)\n",
        "graph_builder = graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder = graph_builder.add_node(\"no_context\", no_context)\n",
        "graph_builder = graph_builder.add_node(\"websearch\", websearch)\n",
        "graph_builder = graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder = graph_builder.add_conditional_edges(\"retrieve\", evaluate_context)\n",
        "graph_builder = graph_builder.add_conditional_edges(\"grade\", evaluate_grade)\n",
        "graph_builder = graph_builder.add_edge(\"no_context\", END)\n",
        "graph_builder = graph_builder.add_edge(\"websearch\", END)\n",
        "graph_builder = graph_builder.add_edge(\"generate\", END) \n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        graph.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "question = \"How does LCEL work?\"\n",
        "\n",
        "response = graph.invoke({\"question\" : question})\n",
        "response[\"response\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
